<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>NEXT</title>
    <url>/2021/06/20/NEXT/</url>
    <content><![CDATA[<p>NEXT 配置修改</p>
<span id="more"></span>
<p>参考地址<br><a href="http://theme-next.iissnan.com/theme-settings.html#rss">http://theme-next.iissnan.com/theme-settings.html#rss</a></p>
<h1 id="1-Next主题风格"><a href="#1-Next主题风格" class="headerlink" title="1.Next主题风格"></a>1.Next主题风格</h1><p>Next提供了四中主题风格scheme，可以在主题配置文件_config.yml文件中进行选择</p>
<p>分别是<code>Muse</code>、<code>Mist</code>、<code>Pisces</code>、<code>Gemini</code></p>
<p>默认时Muse主题，我用的是Gemini主题，所以把Muse注释掉，Gemini去掉注释</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Schemes</span></span><br><span class="line"><span class="meta">#</span><span class="bash">scheme: Muse</span></span><br><span class="line"><span class="meta">#</span><span class="bash">scheme: Mist</span></span><br><span class="line"><span class="meta">#</span><span class="bash">scheme: Pisces</span></span><br><span class="line">scheme: Gemini</span><br></pre></td></tr></table></figure>



<h1 id="2-设置菜单栏"><a href="#2-设置菜单栏" class="headerlink" title="2.设置菜单栏"></a>2.设置菜单栏</h1><h2 id="取消菜单栏注释"><a href="#取消菜单栏注释" class="headerlink" title="取消菜单栏注释"></a>取消菜单栏注释</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">menu:</span><br><span class="line">  home: / || fa fa-home</span><br><span class="line">  about: /about/ || fa fa-user</span><br><span class="line">  tags: /tags/ || fa fa-tags</span><br><span class="line">  categories: /categories/ || fa fa-th</span><br><span class="line">  archives: /archives/ || fa fa-archive</span><br><span class="line"><span class="meta">  #</span><span class="bash">schedule: /schedule/ || fa fa-calendar</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">sitemap: /sitemap.xml || fa fa-sitemap</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">commonweal: /404/ || fa fa-heartbeat</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><strong>在终端窗口下，定位到 Hexo 站点目录下。使用 hexo new page 新建一个页面，命名为 tags ：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd \hexoblog\maybe</span><br><span class="line">hexo new page tags</span><br></pre></td></tr></table></figure>



<p><strong>编辑刚新建的页面，将页面的类型设置为 tags ，主题将自动为这个页面显示标签云。页面内容如下：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: 标签</span><br><span class="line">date: 2021-06-19 14:42:32</span><br><span class="line">type: &quot;tags&quot;</span><br><span class="line">---</span><br></pre></td></tr></table></figure>



<p>*<em><strong>注意：</strong>如果有集成评论服务，页面也会带有评论。 若需要关闭的话，请添加字段 <code>comments</code> 并将值设置为 <code>false</code>，如：</em>*</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: 标签</span><br><span class="line">date: 2021-06-19 14:42:32</span><br><span class="line">type: &quot;tags&quot;</span><br><span class="line">comments: false</span><br><span class="line">---</span><br></pre></td></tr></table></figure>



<h1 id="3-头像修改"><a href="#3-头像修改" class="headerlink" title="3.头像修改"></a>3.头像修改</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">avatar:</span><br><span class="line">  url: /images/avatar.png</span><br></pre></td></tr></table></figure>



<h1 id="4-动态背景"><a href="#4-动态背景" class="headerlink" title="4.动态背景"></a>4.动态背景</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">canvas_ribbon:</span><br><span class="line">  enable: true</span><br></pre></td></tr></table></figure>



<h1 id="5-添加顶部加载条"><a href="#5-添加顶部加载条" class="headerlink" title="5.添加顶部加载条"></a>5.添加顶部加载条</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nprogress:</span><br><span class="line">  enable: true</span><br><span class="line">  spinner: true</span><br></pre></td></tr></table></figure>





<h1 id="6-为博客加上萌萌的宠物"><a href="#6-为博客加上萌萌的宠物" class="headerlink" title="6.为博客加上萌萌的宠物"></a>6.为博客加上萌萌的宠物</h1><p><strong>在终端切换到你的博客的路径里，然后输入如下代码：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install --save hexo-helper-live2d</span><br></pre></td></tr></table></figure>



<h1 id="7-添加搜索功能"><a href="#7-添加搜索功能" class="headerlink" title="7.添加搜索功能"></a>7.添加搜索功能</h1><p><strong>1、安装 hexo-generator-searchdb 插件</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-searchdb --save</span><br></pre></td></tr></table></figure>
<p><strong>2、打开 主题配置文件 找到Local search，将enable设置为true</strong></p>
<h1 id="8-显示当然浏览进度"><a href="#8-显示当然浏览进度" class="headerlink" title="8.显示当然浏览进度"></a>8.显示当然浏览进度</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">back2top:</span><br><span class="line">  enable: true							</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Back to top <span class="keyword">in</span> sidebar.</span></span><br><span class="line">  sidebar: false</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Scroll percent label <span class="keyword">in</span> b2t button.</span></span><br><span class="line">  scrollpercent: true					</span><br></pre></td></tr></table></figure>



<h1 id="9-设置已读进度条"><a href="#9-设置已读进度条" class="headerlink" title="9.设置已读进度条"></a>9.设置已读进度条</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Reading progress bar</span></span><br><span class="line">reading_progress:</span><br><span class="line">  enable: true</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Available values: left | right</span></span><br><span class="line">  startAt: left</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Available values: top | bottom</span></span><br><span class="line">  position: top</span><br><span class="line">  reversed: false</span><br><span class="line">  color: &quot;#37c6c0&quot;</span><br><span class="line">  height: 3px</span><br></pre></td></tr></table></figure>



<h1 id="10-打赏设置"><a href="#10-打赏设置" class="headerlink" title="10.打赏设置"></a>10.打赏设置</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">reward_settings:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> If <span class="literal">true</span>, a donate button will be displayed <span class="keyword">in</span> every article by default.</span></span><br><span class="line">  enable: true</span><br><span class="line">  animation: true</span><br><span class="line">  comment: 请作者喝杯茶吧</span><br><span class="line"><span class="meta">  #</span><span class="bash">comment: Buy me a coffee</span></span><br><span class="line"></span><br><span class="line">reward:</span><br><span class="line">  wechatpay: /images/wechatpay.png</span><br><span class="line"><span class="meta">  #</span><span class="bash">alipay: /images/alipay.png</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">paypal: /images/paypal.png</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">bitcoin: /images/bitcoin.png</span></span><br><span class="line"> </span><br><span class="line">自己获取自己的支付收款码，放置在next/source/images中</span><br></pre></td></tr></table></figure>



<h1 id="11-自定义博客图标"><a href="#11-自定义博客图标" class="headerlink" title="11.自定义博客图标"></a>11.自定义博客图标</h1><p><strong>博客网站的图标可以在iconfont等网站选择和制作图标</strong></p>
<p><strong>文件路径：<code>\themes\next\source</code>，images修改主题images下文件替换</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">favicon:</span><br><span class="line">  small: /images/favicon-16x16-next.png</span><br><span class="line">  medium: /images/favicon-32x32-next.png</span><br><span class="line">  apple_touch_icon: /images/apple-touch-icon-next.png</span><br><span class="line">  safari_pinned_tab: /images/logo.svg</span><br><span class="line"><span class="meta">  #</span><span class="bash">android_manifest: /manifest.json</span></span><br></pre></td></tr></table></figure>



<h1 id="12-开启站点阅读时间"><a href="#12-开启站点阅读时间" class="headerlink" title="12.开启站点阅读时间"></a>12.开启站点阅读时间</h1><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">npm</span> <span class="string">install</span> <span class="string">hexo-word-counter</span></span><br><span class="line"><span class="string">hexo</span> <span class="string">clean</span></span><br><span class="line"></span><br><span class="line"><span class="attr">symbols_count_time:</span></span><br><span class="line">  <span class="attr">separated_meta:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">item_text_total:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>



<h2 id="12-1-页面阅读统计-不蒜子统计"><a href="#12-1-页面阅读统计-不蒜子统计" class="headerlink" title="12.1 页面阅读统计 不蒜子统计"></a>12.1 页面阅读统计 不蒜子统计</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">busuanzi_count:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">false</span>              	   <span class="comment"># 设true 开启</span></span><br><span class="line">  <span class="attr">total_visitors:</span> <span class="literal">true</span>      	   <span class="comment"># 总阅读人数（uv数）</span></span><br><span class="line">  <span class="attr">total_visitors_icon:</span> <span class="string">fa</span> <span class="string">fa-user</span>  <span class="comment"># 阅读总人数的图标</span></span><br><span class="line">  <span class="attr">total_views:</span> <span class="literal">true</span>         	   <span class="comment"># 总阅读次数（pv数）</span></span><br><span class="line">  <span class="attr">total_views_icon:</span> <span class="string">fa</span> <span class="string">fa-eye</span>      <span class="comment"># 阅读总次数的图标</span></span><br><span class="line">  <span class="attr">post_views:</span> <span class="literal">true</span>         		   <span class="comment"># 开启内容阅读次数</span></span><br><span class="line">  <span class="attr">post_views_icon:</span> <span class="string">far</span> <span class="string">fa-eye</span>      <span class="comment"># 内容页阅读数的图标</span></span><br></pre></td></tr></table></figure>



<h1 id="13-文章原创声明"><a href="#13-文章原创声明" class="headerlink" title="13.文章原创声明"></a>13.文章原创声明</h1><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Creative Commons 4.0 International License.</span></span><br><span class="line"><span class="comment"># See: https://creativecommons.org/about/cclicenses/</span></span><br><span class="line"><span class="attr">creative_commons:</span></span><br><span class="line">  <span class="comment"># Available values: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | cc-zero</span></span><br><span class="line">  <span class="attr">license:</span> <span class="string">by-nc-sa</span></span><br><span class="line">  <span class="comment"># Available values: big | small</span></span><br><span class="line">  <span class="attr">size:</span> <span class="string">small</span></span><br><span class="line">  <span class="attr">sidebar:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">post:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># You can set a language value if you prefer a translated version of CC license, e.g. deed.zh</span></span><br><span class="line">  <span class="comment"># CC licenses are available in 39 languages, you can find the specific and correct abbreviation you need on https://creativecommons.org</span></span><br><span class="line">  <span class="attr">language:</span></span><br></pre></td></tr></table></figure>





<h1 id="14-修改底部标签样式"><a href="#14-修改底部标签样式" class="headerlink" title="14.修改底部标签样式"></a>14.修改底部标签样式</h1><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Use icon instead of the symbol # to indicate the tag at the bottom of the post</span></span><br><span class="line"><span class="attr">tag_icon:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>



<h1 id="15-开启代码复制"><a href="#15-开启代码复制" class="headerlink" title="15.开启代码复制"></a>15.开启代码复制</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">codeblock:</span><br><span class="line">  copy_button:</span><br><span class="line">    enable: true</span><br></pre></td></tr></table></figure>



<h1 id="16-鼠标点击特效"><a href="#16-鼠标点击特效" class="headerlink" title="16.鼠标点击特效"></a>16.鼠标点击特效</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install next-theme/hexo-next-fireworks</span><br></pre></td></tr></table></figure>



<h1 id="17-GitHub-Fork-Me"><a href="#17-GitHub-Fork-Me" class="headerlink" title="17.GitHub Fork Me"></a>17.GitHub Fork Me</h1><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># `Follow me on GitHub` banner in the top-right corner.</span></span><br><span class="line"><span class="attr">github_banner:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">permalink:</span> <span class="string">https://github.com/maybeYo</span></span><br><span class="line">  <span class="attr">title:</span> <span class="string">Follow</span> <span class="string">me</span> <span class="string">on</span> <span class="string">GitHub</span></span><br></pre></td></tr></table></figure>



<h1 id="18-bookmark"><a href="#18-bookmark" class="headerlink" title="18.bookmark"></a>18.bookmark</h1><p>Bookmark是一个插件，允许用户保存他们的阅读进度。用户只需单击页面左上角的书签图标即可保存滚动位置。当他们下次访问您的博客时，他们可以自动恢复每个页面的最后滚动位置。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Bookmark Support</span></span><br><span class="line"><span class="attr">bookmark:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Customize the color of the bookmark.</span></span><br><span class="line">  <span class="attr">color:</span> <span class="string">&quot;#222&quot;</span></span><br><span class="line">  <span class="comment"># If auto, save the reading progress when closing the page or clicking the bookmark-icon.</span></span><br><span class="line">  <span class="comment"># If manual, only save it by clicking the bookmark-icon.</span></span><br><span class="line">  <span class="attr">save:</span> <span class="string">auto</span></span><br></pre></td></tr></table></figure>



<h1 id="19-添加lazyload"><a href="#19-添加lazyload" class="headerlink" title="19.添加lazyload"></a>19.添加lazyload</h1><p>对于图片进行延迟加载，访问到图片位置时才去请求图片资源，这样可以提高博客的访问速度，节省流量。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/theme-next/theme-next-jquery-lazyload source/lib/jquery_laz</span><br></pre></td></tr></table></figure>



<p>主题配置文件:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Vanilla JavaScript plugin for lazyloading images.</span></span><br><span class="line"><span class="comment"># For more information: https://apoorv.pro/lozad.js/demo/</span></span><br><span class="line"><span class="attr">lazyload:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>



<h1 id="20-主题及标题栏背景图"><a href="#20-主题及标题栏背景图" class="headerlink" title="20.主题及标题栏背景图"></a>20.主题及标题栏背景图</h1><blockquote>
<p>首先主题配置文件取消注释</p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">custom_file_path:</span></span><br><span class="line">  <span class="attr">style:</span> <span class="string">source/_data/styles.styl</span></span><br></pre></td></tr></table></figure>



<blockquote>
<p>在路径<code>~/hexo_blog/source/_data</code>创建/修改 styles.styl文件，并添加以下内容</p>
</blockquote>
<p>参考链接：<a href="https://bella722.github.io/post/4f44d92e.html">博客参考：bella722.github.io</a></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">// 添加背景图片</span><br><span class="line"><span class="selector-tag">body</span> &#123;</span><br><span class="line">      <span class="attribute">background</span>: <span class="built_in">url</span>(<span class="string">https://source.unsplash.com/random/1600x900?wallpapers</span>);//自己喜欢的图片地址</span><br><span class="line">      <span class="attribute">background-size</span>: cover;</span><br><span class="line">      <span class="attribute">background-repeat</span>: no-repeat;</span><br><span class="line">      <span class="attribute">background-attachment</span>: fixed;</span><br><span class="line">      <span class="attribute">background-position</span>: <span class="number">50%</span> <span class="number">50%</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//首页banner渐变色</span><br><span class="line"><span class="selector-class">.site-brand-container</span> &#123;</span><br><span class="line">    <span class="attribute">background</span>: <span class="built_in">linear-gradient</span>(<span class="number">200deg</span>, <span class="number">#f58220</span>, <span class="number">#f58220</span> );</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 修改主体透明度</span><br><span class="line"><span class="selector-class">.main-inner</span>&#123;</span><br><span class="line">    <span class="attribute">background</span>: <span class="number">#fff</span>;</span><br><span class="line">    <span class="attribute">opacity</span>: <span class="number">0.95</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 修改菜单栏透明度，会引起本地搜索菜单bug</span><br><span class="line">//<span class="selector-class">.header-inner</span> &#123;</span><br><span class="line">//    <span class="attribute">opacity</span>: <span class="number">0.95</span>;</span><br><span class="line">//&#125;</span><br><span class="line"></span><br><span class="line">// 主页文章添加阴影效果</span><br><span class="line"><span class="selector-class">.post</span> &#123;</span><br><span class="line">   <span class="attribute">margin-top</span>: <span class="number">60px</span>;</span><br><span class="line">   <span class="attribute">margin-bottom</span>: <span class="number">60px</span>;</span><br><span class="line">   <span class="attribute">padding</span>: <span class="number">25px</span>;</span><br><span class="line">   -webkit-<span class="attribute">box-shadow</span>: <span class="number">0</span> <span class="number">0</span> <span class="number">5px</span> <span class="built_in">rgba</span>(<span class="number">202</span>, <span class="number">203</span>, <span class="number">203</span>, .<span class="number">5</span>);</span><br><span class="line">   -moz-<span class="attribute">box-shadow</span>: <span class="number">0</span> <span class="number">0</span> <span class="number">5px</span> <span class="built_in">rgba</span>(<span class="number">202</span>, <span class="number">203</span>, <span class="number">204</span>, .<span class="number">5</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="设置所有边框为圆角"><a href="#设置所有边框为圆角" class="headerlink" title="设置所有边框为圆角"></a><strong>设置所有边框为圆角</strong></h2><p>打开文件，路径：<code>\themes\next\source\css_variables\Gemini.styl </code>，添加以下代码：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">//</span> <span class="string">修改主题页面布局为圆角</span></span><br><span class="line"><span class="string">$border-radius-inner</span> <span class="string">=</span> <span class="string">15px</span> <span class="string">15px</span> <span class="string">15px</span> <span class="string">15px;</span></span><br><span class="line"><span class="string">$border-radius</span> <span class="string">=</span> <span class="string">15px;</span></span><br></pre></td></tr></table></figure>





<h1 id="21-开启文章目录"><a href="#21-开启文章目录" class="headerlink" title="21.开启文章目录"></a>21.开启文章目录</h1><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">toc:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Automatically add list number to toc.</span></span><br><span class="line">  <span class="attr">number:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># If true, all words will placed on next lines if header width longer then sidebar width.</span></span><br><span class="line">  <span class="attr">wrap:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># If true, all level of TOC in a post will be displayed, rather than the activated part of it.</span></span><br><span class="line">  <span class="attr">expand_all:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Maximum heading depth of generated toc.</span></span><br><span class="line">  <span class="attr">max_depth:</span> <span class="number">6</span></span><br></pre></td></tr></table></figure>



<h1 id="22-foot页脚设置"><a href="#22-foot页脚设置" class="headerlink" title="22.foot页脚设置"></a>22.foot页脚设置</h1><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">footer:</span></span><br><span class="line">  <span class="comment"># Specify the year when the site was setup. If not defined, current year will be used.</span></span><br><span class="line">  <span class="comment">#since: 2020</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Icon between year and copyright info.</span></span><br><span class="line">  <span class="attr">icon:</span></span><br><span class="line">    <span class="comment"># Icon name in Font Awesome. See: https://fontawesome.com/icons</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">fa</span> <span class="string">fa-heart</span></span><br><span class="line">    <span class="comment"># If you want to animate the icon, set it to true.</span></span><br><span class="line">    <span class="comment">## 图标的一个动画效果，类似于心跳</span></span><br><span class="line">    <span class="attr">animated:</span> <span class="literal">true</span></span><br><span class="line">    <span class="comment"># Change the color of icon, using Hex Code.</span></span><br><span class="line">    <span class="comment"># 图标颜色，可格局需要自行修改</span></span><br><span class="line">    <span class="attr">color:</span> <span class="string">&quot;#ff0000&quot;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># If not defined, `author` from Hexo `_config.yml` will be used.</span></span><br><span class="line">  <span class="attr">copyright:</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Powered by Hexo &amp; NexT</span></span><br><span class="line">  <span class="comment"># Powered by Hexo 字样，不喜欢可以设置为 false</span></span><br><span class="line">  <span class="attr">powered:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Beian ICP and gongan information for Chinese users. See: https://beian.miit.gov.cn, http://www.beian.gov.cn</span></span><br><span class="line"> <span class="comment">#备案信息，如果网站有备案号，可以在这里填写备案号</span></span><br><span class="line">  <span class="attr">beian:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">icp:</span></span><br><span class="line">    <span class="comment"># The digit in the num of gongan beian.</span></span><br><span class="line">    <span class="attr">gongan_id:</span></span><br><span class="line">    <span class="comment"># The full num of gongan beian.</span></span><br><span class="line">    <span class="attr">gongan_num:</span></span><br><span class="line">    <span class="comment"># The icon for gongan beian. See: http://www.beian.gov.cn/portal/download</span></span><br><span class="line">    <span class="attr">gongan_icon_url:</span></span><br></pre></td></tr></table></figure>



<h1 id="23-标签云"><a href="#23-标签云" class="headerlink" title="23.标签云"></a>23.标签云</h1><p>参考地址：</p>
<p><a href="https://github.com/D0n9X1n/hexo-tag-cloud">github参考</a></p>
<p><strong>下载插件</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install hexo-tag-cloud --save</span><br></pre></td></tr></table></figure>



<p><strong>将以下代码插入到<code>next/layout/_macro/sidebar.swig</code></strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">&#123;% if site<span class="selector-class">.tags</span><span class="selector-class">.length</span> &gt; <span class="number">1</span> %&#125;</span><br><span class="line">  &lt;script type=&quot;text/javascript&quot; charset=&quot;utf-<span class="number">8</span>&quot; <span class="attribute">src</span>=&quot;&#123;&#123; url_for(&#x27;/js/tagcloud<span class="selector-class">.js</span>&#x27;) &#125;&#125;&quot;&gt;&lt;/script&gt;</span><br><span class="line">  &lt;script type=&quot;text/javascript&quot; charset=&quot;utf-<span class="number">8</span>&quot; <span class="attribute">src</span>=&quot;&#123;&#123; url_for(&#x27;/js/tagcanvas<span class="selector-class">.js</span>&#x27;) &#125;&#125;&quot;&gt;&lt;/script&gt;</span><br><span class="line">  &lt;<span class="selector-tag">div</span> class=&quot;widget-wrap&quot;&gt;</span><br><span class="line">    &lt;<span class="selector-tag">h3</span> class=&quot;widget-title&quot;&gt;Tag Cloud&lt;/<span class="selector-tag">h3</span>&gt;</span><br><span class="line">    &lt;<span class="selector-tag">div</span> id=&quot;myCanvasContainer&quot; class=&quot;widget tagcloud&quot;&gt;</span><br><span class="line">      &lt;<span class="selector-tag">canvas</span> <span class="attribute">width</span>=&quot;<span class="number">250</span>&quot; <span class="attribute">height</span>=&quot;<span class="number">250</span>&quot; id=&quot;resCanvas&quot; style=&quot;<span class="attribute">width</span>:<span class="number">100%</span><span class="string">&quot;&gt;</span></span><br><span class="line"><span class="string">        &#123;&#123; list_tags() &#125;&#125;</span></span><br><span class="line"><span class="string">      &lt;/canvas&gt;</span></span><br><span class="line"><span class="string">    &lt;/div&gt;</span></span><br><span class="line"><span class="string">  &lt;/div&gt;</span></span><br><span class="line"><span class="string">&#123;% endif %&#125;</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure>



<h1 id="24-侧边栏社交链接"><a href="#24-侧边栏社交链接" class="headerlink" title="24.侧边栏社交链接"></a>24.侧边栏社交链接</h1><p><strong>修改 <code>themes\next\_config.yml </code>主题配置文件</strong></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Social Links</span></span><br><span class="line"><span class="comment"># Usage: `Key: permalink || icon`</span></span><br><span class="line"><span class="comment"># Key is the link label showing to end users.</span></span><br><span class="line"><span class="comment"># Value before `||` delimiter is the target permalink, value after `||` delimiter is the name of Font Awesome icon.</span></span><br><span class="line"><span class="attr">social:</span></span><br><span class="line">  <span class="comment">#GitHub: https://github.com/yourname || fab fa-github</span></span><br><span class="line">  <span class="comment">#E-Mail: mailto:yourname@gmail.com || fa fa-envelope</span></span><br><span class="line">  <span class="comment">#Weibo: https://weibo.com/yourname || fab fa-weibo</span></span><br><span class="line">  <span class="comment">#Google: https://plus.google.com/yourname || fab fa-google</span></span><br><span class="line">  <span class="comment">#Twitter: https://twitter.com/yourname || fab fa-twitter</span></span><br><span class="line">  <span class="comment">#FB Page: https://www.facebook.com/yourname || fab fa-facebook</span></span><br><span class="line">  <span class="comment">#StackOverflow: https://stackoverflow.com/yourname || fab fa-stack-overflow</span></span><br><span class="line">  <span class="comment">#YouTube: https://youtube.com/yourname || fab fa-youtube</span></span><br><span class="line">  <span class="comment">#Instagram: https://instagram.com/yourname || fab fa-instagram</span></span><br><span class="line">  <span class="comment">#Skype: skype:yourname?call|chat || fab fa-skype</span></span><br><span class="line">  <span class="attr">QQ:</span> <span class="string">http://wpa.qq.com/msgrd?v=3&amp;uin=此处填写qq账号&amp;site=qq&amp;menu=yes</span> <span class="string">||</span> <span class="string">fab</span> <span class="string">fa-qq</span></span><br><span class="line">  <span class="attr">GitHub:</span> <span class="string">https://github.com/maybeYo</span> <span class="string">||</span> <span class="string">fab</span> <span class="string">fa-github</span></span><br><span class="line"></span><br><span class="line"><span class="attr">social_icons:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">icons_only:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">transition:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###设置友情链接</span></span><br><span class="line"><span class="comment"># Blog rolls</span></span><br><span class="line"><span class="attr">links_settings:</span></span><br><span class="line">  <span class="attr">icon:</span> <span class="string">fa</span> <span class="string">fa-globe</span></span><br><span class="line">  <span class="attr">title:</span> <span class="string">Links</span></span><br><span class="line">  <span class="comment"># Available values: block | inline</span></span><br><span class="line">  <span class="attr">layout:</span> <span class="string">block</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#设置网址</span></span><br><span class="line"><span class="attr">links:</span></span><br><span class="line">  <span class="comment">#Title: https://example.com</span></span><br></pre></td></tr></table></figure>



<h1 id="25-点击图片放大"><a href="#25-点击图片放大" class="headerlink" title="25.点击图片放大"></a>25.点击图片放大</h1><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># FancyBox is a tool that offers a nice and elegant way to add zooming functionality for images.</span></span><br><span class="line"><span class="comment"># For more information: https://fancyapps.com/fancybox/</span></span><br><span class="line"><span class="attr">fancybox:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>NEXT</category>
      </categories>
      <tags>
        <tag>NEXT</tag>
      </tags>
  </entry>
  <entry>
    <title>NEXT-SEO</title>
    <url>/2021/07/16/NEXT-SEO/</url>
    <content><![CDATA[<p>NEXT-SEO</p>
<span id="more"></span>



<p>参考链接：<a href="https://jingyan.baidu.com/article/a3761b2bf716631576f9aa3a.html">百度链接：jingyan.baidu.com</a></p>
<p>参考链接：<a href="https://www.himmy.cn/2019/07/06/hexo%E5%8D%9A%E5%AE%A2%E7%99%BE%E5%BA%A6%E6%94%B6%E5%BD%95/">博客链接：www.himmy.cn</a></p>
<h3 id="链接提交给百度"><a href="#链接提交给百度" class="headerlink" title="链接提交给百度"></a>链接提交给百度</h3><p>在百度中搜索自己博客的域名，如：<a href="https://maybeyo.github.io//">mabeyo.github.io</a>，或者<a href="https://maybeyo.github.io/">site:mabeyo.github.io</a>，如果百度找不到该博客的相关信息就说明你的博客地址还未被百度收录，会有如下提示，按提示点击提交网站到相关页面就可以提交我们的博客地址</p>
<ul>
<li>没有找到该URL。您可以直接访问 <a href="https://maybeyo.github.io/">mabeyo.github.io</a>，还可<a href="https://ziyuan.baidu.com/linksubmit/url">提交网址</a>给我们。</li>
</ul>
<h3 id="添加网站及验证所有权"><a href="#添加网站及验证所有权" class="headerlink" title="添加网站及验证所有权"></a>添加网站及验证所有权</h3><p>登录百度搜索资源平台，然后进入<a href="https://ziyuan.baidu.com/site">站点管理</a>页面，点击添加网站按钮添加我们的博客</p>
<ul>
<li>第一步：输入网站地址，如 <a href="https://maybeyo.github.io//">mabeyo.github.io</a></li>
<li>第二步：选择站点属性，最多可选三项，如影视动漫、信息技术等</li>
<li>第三步：验证网站，就是验证网站的所有权，说明该网站是我们的，这是重点，下面详细说明</li>
</ul>
<p>验证网站有三种方式：文件验证、HTML标签验证、CNAME验证</p>
<p><strong>文件验证</strong></p>
<p>为保持验证通过的状态,成功验证后请不要删除HTML文件</p>
<p>此处用的HTML标签验证</p>
<p>在next主题配置文件中<code>\themes\next\layout\_partials\head\head.njk</code>粘贴验证标签</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">&#123;%- if theme<span class="selector-class">.baidu_site_verification</span> %&#125;</span><br><span class="line">    &lt;meta name=&quot;baidu-site-verification&quot; <span class="attribute">content</span>=&quot;<span class="selector-tag">code</span>-Z5xxxxx&quot; /&gt;</span><br><span class="line">&#123;%- endif %&#125;</span><br></pre></td></tr></table></figure>



<p>在next主题配置文件<code>\themes\next\_config.yaml</code>中修改</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Baidu Webmaster tools verification.</span></span><br><span class="line"><span class="comment"># See: https://ziyuan.baidu.com/site</span></span><br><span class="line"><span class="attr">baidu_site_verification:</span> <span class="string">Z5sxxxxxx</span></span><br></pre></td></tr></table></figure>





<p>重新部署</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo clean all</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure>



<p>访问是否添加成功 <a href="view-source:https://maybeyo.github.io/">view-source:https://maybeyo.github.io/</a></p>
<p>完成验证</p>
<h3 id="链接提交：sitemap"><a href="#链接提交：sitemap" class="headerlink" title="链接提交：sitemap"></a>链接提交：sitemap</h3><p>安装sitemap生成器插件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-sitemap --save</span><br><span class="line">npm install hexo-generator-baidu-sitemap --save</span><br></pre></td></tr></table></figure>



<p>重新generate，会在public目录下生成<code>sitemap.xml</code>、<code>baidusitemap.xml</code>两个文件</p>
<p>sitemap.xml文件内容</p>
<p>重新部署</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo clean all</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure>



<p>最后在自动提交-&gt;sitemap页面填入sitemap的地址</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">maybeyo<span class="selector-class">.github</span><span class="selector-class">.io</span>/sitemap<span class="selector-class">.xml</span></span><br><span class="line">maybeyo<span class="selector-class">.github</span><span class="selector-class">.io</span>/baidusitemap<span class="selector-class">.xml</span></span><br></pre></td></tr></table></figure>















]]></content>
      <categories>
        <category>NEXT</category>
      </categories>
      <tags>
        <tag>NEXT</tag>
      </tags>
  </entry>
  <entry>
    <title>activemq</title>
    <url>/2021/07/28/activemq/</url>
    <content><![CDATA[<p>activemq配置文件</p>
<span id="more"></span>

<p>​    在使用ActiveMQ的时候，一般会对其分配用户和角色来做基本的权限验证，本博文选择自带的JAAS Plugin来完成。本文中ActiveMQ版本选择5.16.0</p>
<p>​    在LINUX上下载解压完ActiveMQ之后进入到conf目录下，其中有四个文件需要特别关注：</p>
<ul>
<li>login.config  - 登录配置</li>
<li>users.properties - 用户密码配置</li>
<li>groups.properties - 用户组配置</li>
<li>activemq.xml - ActiveMQ实例配置</li>
</ul>
<h1 id="login-config"><a href="#login-config" class="headerlink" title="login.config"></a>login.config</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">activemq &#123;</span><br><span class="line">    org.apache.activemq.jaas.PropertiesLoginModule required</span><br><span class="line">        org.apache.activemq.jaas.properties.user=&quot;users.properties&quot;</span><br><span class="line">        org.apache.activemq.jaas.properties.group=&quot;groups.properties&quot;</span><br><span class="line">	reload=true;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<hr>
<p>​    在没有设置<code>java.security.auth.login.config</code>属性时，会默认读取这个文件作为配置；可以看到该文件中，先是定义了一个节点名<code>activemq</code>，第二行表示使用的是<code>PropertiesLoginModule</code>来获取认证信息（其他的方式请参考官网），顾名思义就是从配置文件中读取，所以下面就配置了使用<code>users.properties</code>文件作为用户密码配置，使用<code>groups.properties</code>文件作为用户组配置。默认在当前文件同一目录中查找这两个文件。<code>reload=true</code>，表示可以在运行过程中更改<code>users.properties</code>，<code>groups.properties</code>文件内容，并动态刷新；<strong>不要忘了最后的</strong> <code>&quot;;&quot;</code>。</p>
<hr>
<h1 id="users-properties"><a href="#users-properties" class="headerlink" title="users.properties"></a>users.properties</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># username = password</span></span></span><br><span class="line">admin=admin</span><br><span class="line">wuser=wuser</span><br><span class="line">ruser=ruser</span><br></pre></td></tr></table></figure>

<p>在该文件中定义用户，格式：用户名=密码；</p>
<h1 id="groups-properties"><a href="#groups-properties" class="headerlink" title="groups.properties"></a>groups.properties</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># rolename = username1,username2</span></span></span><br><span class="line">admins=admin</span><br><span class="line">writes=wuser</span><br><span class="line">reads=ruser</span><br></pre></td></tr></table></figure>

<p>在该文件中定义角色，格式：角色名=用户1，用户2…</p>
<h1 id="activemq-xml"><a href="#activemq-xml" class="headerlink" title="activemq.xml"></a>activemq.xml</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">   &lt;persistenceAdapter&gt;</span><br><span class="line">       &lt;kahaDB directory=&quot;$&#123;activemq.data&#125;/kahadb&quot;/&gt;</span><br><span class="line">   &lt;/persistenceAdapter&gt;</span><br><span class="line"></span><br><span class="line">&lt;plugins&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--  use JAAS to authenticate using the login.config file on the classpath to configure JAAS --&gt;</span><br><span class="line">	&lt;jaasAuthenticationPlugin configuration=&quot;activemq&quot; /&gt;</span><br><span class="line">&lt;!--  lets configure a destination based authorization mechanism --&gt;</span><br><span class="line">	&lt;authorizationPlugin&gt;</span><br><span class="line">	   &lt;map&gt;</span><br><span class="line">		&lt;authorizationMap&gt;</span><br><span class="line">			&lt;authorizationEntries&gt;</span><br><span class="line">				&lt;authorizationEntry topic=&quot;&gt;&quot; read=&quot;reads,writes&quot; write=&quot;writes&quot; admin=&quot;writes,admins&quot; /&gt;</span><br><span class="line">				&lt;authorizationEntry queue=&quot;&gt;&quot; read=&quot;reads,writes&quot; write=&quot;writes&quot; admin=&quot;writes,admins&quot; /&gt;</span><br><span class="line">				&lt;authorizationEntry topic=&quot;ActiveMQ.Advisory.&gt;&quot; read=&quot;reads,writes,admins&quot; write=&quot;reads,writes,admins&quot; admin=&quot;reads,writes,admins&quot;/&gt;</span><br><span class="line">				&lt;authorizationEntry queue=&quot;ActiveMQ.Advisory.&gt;&quot; read=&quot;reads,writes,admins&quot; write=&quot;reads,writes,admins&quot; admin=&quot;reads,writes,admins&quot;/&gt;</span><br><span class="line">			&lt;/authorizationEntries&gt;</span><br><span class="line">		&lt;/authorizationMap&gt;</span><br><span class="line">	   &lt;/map&gt;</span><br><span class="line">	&lt;/authorizationPlugin&gt;</span><br><span class="line">&lt;/plugins&gt;</span><br></pre></td></tr></table></figure>

<hr>
<p>​    主要是<code>plugins</code>节点，将其放置在persistenceAdapter节点下面，用于配置权限映射。</p>
<p>​    其中<code>jaasAuthenticationPlugin</code>的<code>configuration</code>属性必须要在<code>login.config</code>文件中存在，上面介绍<code>login.config</code>文件时，定义了一个<code>activemq</code>的节点，所以此处同样需要设置为<code>activemq</code>。</p>
<p>​    下面的authorizationEntry节点中</p>
<hr>
<h2 id="queue-topic"><a href="#queue-topic" class="headerlink" title="queue/topic"></a>queue/topic</h2><p>​    代表权限是作用在queue还是topic上，其值是一个通配符表达式，通配符表达式如下，用于匹配queue/topic的名字。</p>
<table>
<thead>
<tr>
<th>.</th>
<th>分隔符;分隔名字,*,&gt;</th>
</tr>
</thead>
<tbody><tr>
<td>*</td>
<td>匹配任何字符</td>
</tr>
<tr>
<td>&gt;</td>
<td>任何字符直到末尾</td>
</tr>
</tbody></table>
<p>例如:</p>
<p>​    仅单个”&gt;” 和单个”*”都表示匹配全部</p>
<p>​    “PREFIX.&gt;”或”PREFIX.*”都表示以PREFIX开头的中间以”.”分隔；可以匹配： PREFIX , PREFIX.1 , PREFIX.1.2 ；无法匹配： PREFIX1</p>
<p>​    “PREFIX.*.SUFFIX”表示以PREFIX开头，以SUFFIX结尾；可以匹配：PREFIX.1.SUFFIX；无法匹配：PREFIX.1.2.SUFFIX，PREFIX.1.SUFFIX.2</p>
<p>​    注意，如果要使用”&gt;”，那么一定要将其放在表达式的最后。具体信息可以访问<a href="https://activemq.apache.org/wildcards">官网</a>。</p>
<h2 id="read-write-admin"><a href="#read-write-admin" class="headerlink" title="read/write/admin"></a>read/write/admin</h2><table>
<thead>
<tr>
<th>属性</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>read</td>
<td>查看和消费目的地数据</td>
</tr>
<tr>
<td>write</td>
<td>往目的地发送数据</td>
</tr>
<tr>
<td>admin</td>
<td>创建目的地</td>
</tr>
</tbody></table>
<p>​    read/write/admin 其值是角色名，多个使用”,”分隔，角色名在groups.properties文件中配置。<strong>注意：如果目的地还没创建出来的话，拥有write权限的角色是无法往该目的地发送数据的。</strong></p>
<hr>
<p>​    以上，就是ActiveMQ的权限验证配置。如果是配置ActiveMQ WEB端的权限，则需要在jetty.xml 和 jetty-realm.xml中进行配置</p>
<h2 id="1-jetty-xml-配置-ActiveMQ-的web-Console-控制台端口"><a href="#1-jetty-xml-配置-ActiveMQ-的web-Console-控制台端口" class="headerlink" title="1. jetty.xml 配置 ActiveMQ 的web Console 控制台端口:"></a>1. jetty.xml 配置 ActiveMQ 的web Console 控制台端口:</h2><p>在<code>jetty.xml</code>文件中:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;bean id=&quot;jettyPort&quot; class=&quot;org.apache.activemq.web.WebConsolePort&quot; init-method=&quot;start&quot;&gt;</span><br><span class="line">             &lt;!-- the default port number for the web console --&gt;</span><br><span class="line">        &lt;property name=&quot;host&quot; value=&quot;0.0.0.0&quot;/&gt;</span><br><span class="line">        &lt;property name=&quot;port&quot; value=&quot;8161&quot;/&gt;&lt;/bean&gt;</span><br></pre></td></tr></table></figure>



<h2 id="2-jetty-realm-properties-ActiveMQ-的-web-Console-控制台用户名密码配置"><a href="#2-jetty-realm-properties-ActiveMQ-的-web-Console-控制台用户名密码配置" class="headerlink" title="2. jetty-realm.properties ActiveMQ 的 web Console 控制台用户名密码配置:"></a>2. jetty-realm.properties ActiveMQ 的 web Console 控制台用户名密码配置:</h2><p>当登录 <a href="http://localhost:8161/">http://localhost:8161</a> 进入管理界面时,输入用户名密码配置在文件<code>jetty-realm.properties</code>中,添加一个用户为”aries”密码为”123”的管理员如下:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Defines users that can access the web (console, demo, etc.)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> username: password [,rolename ...]</span></span><br><span class="line">admin: admin, admin</span><br><span class="line">user: user, user</span><br><span class="line">aries: 123, admin</span><br></pre></td></tr></table></figure>

<hr>
<p>第一列为用户名,第二列是密码,第三列表示角色。</p>
<hr>
<h2 id="3-设置MQ的持久化方式"><a href="#3-设置MQ的持久化方式" class="headerlink" title="3.设置MQ的持久化方式:"></a>3.设置MQ的持久化方式:</h2><p>ActiveMQ 默认使用 <code>KaHadb</code> 进行持久化消息存储, 配置在 <code>ActiveMQ.xml</code> 文件中:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;persistenceAdapter&gt;</span><br><span class="line">            &lt;kahaDB directory=&quot;$&#123;activemq.data&#125;/kahadb&quot;/&gt;</span><br><span class="line">&lt;/persistenceAdapter&gt;</span><br></pre></td></tr></table></figure>



<p> 现在我们将持久化存储方式修改为 <code>mysql</code> ,则修改上面的配置文件如下:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;persistenceAdapter&gt;</span><br><span class="line"></span><br><span class="line">         &lt;jdbcPersistenceAdapter  dataSource=&quot;#derby-ds&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;/persistenceAdapter&gt;</span><br></pre></td></tr></table></figure>



<p>同时添加<code>mysq数据源</code>的配置:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;bean id=&quot;derby-ds&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot; destroy-method=&quot;close&quot;&gt;</span><br><span class="line">　　&lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt;</span><br><span class="line">　　&lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/activemq?relaxAutoCommit=true&quot;/&gt;</span><br><span class="line">　　&lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt;</span><br><span class="line">　　&lt;property name=&quot;password&quot; value=&quot;123&quot;/&gt;</span><br><span class="line">　　&lt;property name=&quot;maxActive&quot; value=&quot;200&quot;/&gt;</span><br><span class="line">　　&lt;property name=&quot;poolPreparedStatements&quot; value=&quot;true&quot;/&gt;</span><br><span class="line">&lt;/bean&gt;</span><br></pre></td></tr></table></figure>



<p>添加mysql驱动等依赖包到ActiveMQ的lib目录下:</p>
<ul>
<li><p>mysql-connector-<a href="http://lib.csdn.net/base/javase">Java</a>-5.1.30-bin.jar</p>
</li>
<li><p>commons-dbcp-1.4.jar</p>
</li>
<li><p>commons-pool-1.6.jar</p>
</li>
</ul>
<p>​    在 mysql 中创建  activemq  数据库,然后启动 ActiveMQ，如果数据test库中生成 <code>activemq_acks</code>，<code>activemq_lock</code>，<code>activemq_msgs</code>三张表,则证明mysql持久化存储配置完成。</p>
<h3 id="3-配置消息接收发送顺序按照优先级进行"><a href="#3-配置消息接收发送顺序按照优先级进行" class="headerlink" title="3.配置消息接收发送顺序按照优先级进行:"></a>3.配置消息接收发送顺序按照优先级进行:</h3><p>​    在发送消息的时候我们可以设置消息的优先级,来确定消息的接收顺序(对于单个MQ来说,如果是集群就不能确定优先级顺序了),优先级的使用需要在ActiveMQ.xml配置文件中进行开启:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;policyEntry queue=&quot;&gt;&quot;  prioritizedMessages=&quot;true&quot; /&gt;  </span><br></pre></td></tr></table></figure>



<p>参考连接：<a href="https://blog.csdn.net/qq_38167579/article/details/115530052">CSDN    https://blog.csdn.net</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2021/06/19/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>GRE隧道</title>
    <url>/2021/09/18/gre/</url>
    <content><![CDATA[<p>GRE隧道</p>
<span id="more"></span>

<p>其他国家的互联网如同一个孤岛。要想访问国外网站异常的缓慢，甚至被和谐了。可以建立一条隧道来避免这种情况，下面说说GRE隧道如何建立。</p>
<p><strong>1. GRE介绍</strong></p>
<p>GRE隧道是一种IP-over-IP的隧道，是通用路由封装协议，可以对某些网路层协议的数据报进行封装，使这些被封装的数据报能够在IPv4/IPv6 网络中传输。</p>
<p>Tunnel 是一个虚拟的点对点的连接，提供了一条通路使封装的数据报文能够在这个通路上传输，并且在一个Tunnel 的两端分别对数据报进行封装及解封装。　一个X协议的报文要想穿越IP网络在Tunnel中传输，必须要经过加封装与解封装两个过程。</p>
<p>要在 Linux 上创建GRE隧道，需要ip_gre内核模块，它是GRE通过IPv4隧道的驱动程序。</p>
<p><strong>2. 查看是否有加载ip_gre模块</strong></p>
 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> modprobe ip_gre</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> lsmod | grep gre</span></span><br><span class="line">ip_gre         22432 0</span><br><span class="line">gre          12989 1 ip_gre</span><br></pre></td></tr></table></figure>



<p><strong>3. 创建步骤</strong></p>
<p>环境如下：</p>
<table>
<thead>
<tr>
<th><strong>host A :</strong></th>
<th><strong>10.253.154.5</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>host B:</strong></td>
<td><strong>10.253.54.154</strong></td>
</tr>
</tbody></table>
<p><strong>在host A上面：</strong></p>
 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ip tunnel add gre1 mode gre remote 10.253.54.154 local 10.253.154.5 ttl 255</span><br><span class="line">ip link set gre1 up</span><br><span class="line">ip addr add 10.10.10.1 peer 10.10.10.2 dev gre1</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<p><strong>创建一个GRE类型隧道设备gre0, 并设置对端IP为10.253.54.154。隧道数据包将被从10.253.154.5也就是本地IP地址发起，其TTL字段被设置为255。隧道设备分配的IP地址为10.10.10.1，掩码为255.255.255.0。</strong></p>
<p><strong>在host B上面：</strong></p>
 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ip tunnel add gre1 mode gre remote  10.253.154.5 local 10.253.54.154 ttl 255</span><br><span class="line">ip link set gre1 up</span><br><span class="line">ip addr add 10.10.10.2 peer 10.10.10.1 dev gre1</span><br></pre></td></tr></table></figure>



<p><strong>此时，host A 和 host B 建立起GRE隧道了。</strong></p>
<p><strong>4. 检测连通性</strong></p>
 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">  ping 10.10.10.2 (host A)</span><br><span class="line">  PING 10.10.10.2 (10.10.10.2) 56(84) bytes of data.</span><br><span class="line">  64 bytes from 10.10.10.2: icmp_req=1 ttl=64 time=0.319 ms</span><br><span class="line">  64 bytes from 10.10.10.2: icmp_req=2 ttl=64 time=0.296 ms</span><br><span class="line">  64 bytes from 10.10.10.2: icmp_req=3 ttl=64 time=0.287 ms</span><br></pre></td></tr></table></figure>



<p><strong>5.撤销GRE隧道</strong></p>
<p><strong>在任一一端操作下面命令</strong></p>
 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ip link set gre1 down</span><br><span class="line">ip tunnel del gre1</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo资源文件夹</title>
    <url>/2021/07/20/hexo%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6%E5%A4%B9/</url>
    <content><![CDATA[<p>hexo资源文件夹</p>
<span id="more"></span>

<p>参考地址：<a href="https://hexo.io/zh-cn/docs/asset-folders">官方地址 hexo.io/zh-cn/docs/asset-folders</a></p>
<p>​    资源（Asset）代表 <code>source</code> 文件夹中除了文章以外的所有文件，例如图片、CSS、JS 文件等。比方说，如果你的Hexo项目中只有少量图片，那最简单的方法就是将它们放在 <code>source/images</code> 文件夹中。然后通过类似于 <code>![](/images/image.jpg)</code> 的方法访问它们。</p>
<p>对于那些想要更有规律地提供图片和其他资源以及想要将他们的资源分布在各个文章上的人来说，Hexo也提供了更组织化的方式来管理资源。这个稍微有些复杂但是管理资源非常方便的功能可以通过将 <code>config.yml</code> 文件中的 <code>post_asset_folder</code> 选项设为 <code>true</code> 来打开。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">_config.ymlpost_asset_folder:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>当资源文件管理功能打开后，Hexo将会在你每一次通过 <code>hexo new [layout] &lt;title&gt;</code> 命令创建新文章时自动创建一个文件夹。这个资源文件夹将会有与这个文章文件一样的名字。将所有与你的文章有关的资源放在这个关联文件夹中之后，你可以通过相对路径来引用它们，这样你就得到了一个更简单而且方便得多的工作流。</p>
<h2 id="相对路径引用的标签插件"><a href="#相对路径引用的标签插件" class="headerlink" title="相对路径引用的标签插件"></a>相对路径引用的标签插件</h2><p>通过常规的 markdown 语法和相对路径来引用图片和其它资源可能会导致它们在存档页或者主页上显示不正确。在Hexo 2时代，社区创建了很多插件来解决这个问题。但是，随着Hexo 3 的发布，许多新的<a href="https://hexo.io/docs/tag-plugins#Include-Assets">标签插件</a>被加入到了核心代码中。这使得你可以更简单地在文章中引用你的资源。</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">&#123;% asset_path slug %&#125;</span><br><span class="line">&#123;% asset_img slug <span class="selector-attr">[title]</span> %&#125;</span><br><span class="line">&#123;% asset_link slug <span class="selector-attr">[title]</span> %&#125;</span><br></pre></td></tr></table></figure>

<p>比如说：当你打开文章资源文件夹功能后，你把一个 <code>example.jpg</code> 图片放在了你的资源文件夹中，如果通过使用相对路径的常规 markdown 语法 <code>![](example.jpg)</code> ，它将 <em>不会</em> 出现在首页上。（但是它会在文章中按你期待的方式工作）</p>
<p>正确的引用图片方式是使用下列的标签插件而不是 markdown ：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">&#123;% asset_img example<span class="selector-class">.jpg</span> This is an example image %&#125;</span><br></pre></td></tr></table></figure>

<p>通过这种方式，图片将会同时出现在文章和主页以及归档页中。</p>
<h2 id="Embedding-an-image-using-markdown"><a href="#Embedding-an-image-using-markdown" class="headerlink" title="Embedding an image using markdown"></a>Embedding an image using markdown</h2><p><a href="https://github.com/hexojs/hexo-renderer-marked">hexo-renderer-marked</a> 3.1.0 introduced a new option that allows you to embed an image in markdown without using <code>asset_img</code> tag plugin.</p>
<p>To enable:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">_config.ymlpost_asset_folder:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">marked:</span></span><br><span class="line">  <span class="attr">prependRoot:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">postAsset:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>Once enabled, an asset image will be automatically resolved to its corresponding post’s path. For example, “image.jpg” is located at “/2020/01/02/foo/image.jpg”, meaning it is an asset image of “/2020/01/02/foo/“ post, <code>![](image.jpg)</code> will be rendered as <code>&lt;img src=&quot;/2020/01/02/foo/image.jpg&quot;&gt;</code>.</p>
]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s常见总结1</title>
    <url>/2021/07/17/k8s%E5%B8%B8%E8%A7%81%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<p>k8s常见总结1</p>
<span id="more"></span>

<h1 id="1-什么是Kubernetes？"><a href="#1-什么是Kubernetes？" class="headerlink" title="1.什么是Kubernetes？"></a>1.什么是Kubernetes？</h1><p>​    Kubernetes是一个开源容器管理工具，负责容器部署，容器扩缩容以及负载平衡。作为Google的创意之作，它提供了出色的社区，并与所有云提供商合作。因此，我们可以说Kubernetes不是<em>一个容器化平台，而是一个多容器管理解决方案。</em></p>
<h1 id="2-在主机和容器上部署应用程序有什么区别？"><a href="#2-在主机和容器上部署应用程序有什么区别？" class="headerlink" title="2.在主机和容器上部署应用程序有什么区别？"></a>2.在主机和容器上部署应用程序有什么区别？</h1><p>​    主机上部署应用程序。这种架构将具有操作系统，然后操作系统将具有内核，该内核将在应用程序所需的操作系统上安装各种库。因此，在这种框架中，您可以拥有n个应用程序，并且所有应用程序将共享该操作系统中存在的库，而在容器中部署应用程序时，体系结构则略有不同。</p>
<p>​    这种架构将有一个内核，这是唯一一个在所有应用程序之间唯一共同的东西。因此，如果有一个需要Java的特定应用程序，那么我们将获得访问Java的特定应用程序，如果有另一个需要Python的应用程序，则只有该特定应用程序才能访问Python。</p>
<p>​    容器化的，这块与其他应用程序隔离。因此，应用程序具有与系统其余部分隔离的必要库和二进制文件，并且不能被任何其他应用程序侵占。</p>
<h1 id="3-Kubernetes如何简化容器化部署？"><a href="#3-Kubernetes如何简化容器化部署？" class="headerlink" title="3.Kubernetes如何简化容器化部署？"></a>3.Kubernetes如何简化容器化部署？</h1><p>​    由于典型应用程序将具有跨多个主机运行的容器集群，因此所有这些容器都需要相互通信。因此，要做到这一点，你需要一些能够负载平衡，扩展和监控容器的东西。由于Kubernetes与云无关并且可以在任何公共/私有提供商上运行，因此必须是您简化容器化部署的选择。</p>
<h1 id="4-Kubernetes的集群了解"><a href="#4-Kubernetes的集群了解" class="headerlink" title="4.Kubernetes的集群了解"></a>4.Kubernetes的集群了解</h1><p>​    Kubernetes背后的基础是我们可以实施所需的状态管理，我的意思是我们可以提供特定配置的集群服务，并且集群服务将在基础架构中运行并运行该配置。</p>
<p>​    因此，部署文件将具有提供给集群服务所需的所有配置。现在，部署文件将被提供给API，然后由集群服务决定如何在环境中安排这些pod，并确保正确运行的pod数量。</p>
<p>​    因此，位于服务前面的API，工作节点和节点运行的Kubelet进程，共同构成了Kubernetes集群。</p>
<h1 id="5-什么是Google容器引擎？"><a href="#5-什么是Google容器引擎？" class="headerlink" title="5.什么是Google容器引擎？"></a>5.什么是Google容器引擎？</h1><p>​    Google Container Engine（GKE）是Docker容器和集群的开源管理平台。这个基于Kubernetes的引擎仅支持在Google的公共云服务中运行的群集。</p>
<h1 id="6-什么是Minikube？"><a href="#6-什么是Minikube？" class="headerlink" title="6.什么是Minikube？"></a>6.什么是Minikube？</h1><p>​    Minikube是一种工具，可以在本地轻松运行Kubernetes。这将在虚拟机中运行单节点Kubernetes群集。</p>
<h1 id="7-什么是Kubectl？"><a href="#7-什么是Kubectl？" class="headerlink" title="7.什么是Kubectl？"></a>7.什么是Kubectl？</h1><p>​    Kubectl是一个平台，您可以使用该平台将命令传递给集群。因此，它基本上为CLI提供了针对Kubernetes集群运行命令的方法，以及创建和管理Kubernetes组件的各种方法。</p>
<h1 id="8-什么是Kubelet？"><a href="#8-什么是Kubelet？" class="headerlink" title="8.什么是Kubelet？"></a>8.什么是Kubelet？</h1><p>​    这是一个代理服务，它在每个节点上运行，并使从服务器与主服务器通信。因此，Kubelet处理PodSpec中提供给它的容器的描述，并确保PodSpec中描述的容器运行正常。</p>
<h1 id="9-Kubernetes-Architecture的不同组件有哪些？"><a href="#9-Kubernetes-Architecture的不同组件有哪些？" class="headerlink" title="9.Kubernetes Architecture的不同组件有哪些？"></a>9.Kubernetes Architecture的不同组件有哪些？</h1><p>​    Kubernetes Architecture主要有两个组件 - 主节点和工作节点。如下图所示，master和worker节点中包含许多内置组件。主节点具有kube-controller-manager，kube-apiserver，kube-scheduler等。而工作节点具有在每个节点上运行的kubelet和kube-proxy。</p>
<h1 id="10-你对Kube-proxy有什么了解？"><a href="#10-你对Kube-proxy有什么了解？" class="headerlink" title="10.你对Kube-proxy有什么了解？"></a>10.你对<code>Kube-proxy</code>有什么了解？</h1><p>​    Kube-proxy可以在每个节点上运行，并且可以跨后端网络服务进行简单的TCP / UDP数据包转发。基本上，它是一个网络代理，它反映了每个节点上Kubernetes API中配置的服务。因此，Docker可链接的兼容环境变量提供由代理打开的群集IP和端口。</p>
<h1 id="11-Kubernetes中主节点的工作情况？"><a href="#11-Kubernetes中主节点的工作情况？" class="headerlink" title="11.Kubernetes中主节点的工作情况？"></a>11.Kubernetes中主节点的工作情况？</h1><p>​    Kubernetes master控制容器存在的节点和节点内部。现在，这些单独的容器包含在容器内部和每个容器内部，您可以根据配置和要求拥有不同数量的容器。因此，如果必须部署pod，则可以使用用户界面或命令行界面部署它们。然后，在节点上调度这些pod，并根据资源需求，将pod分配给这些节点。kube-apiserver确保在Kubernetes节点和主组件之间建立通信。</p>
<h1 id="12-kube-apiserver和kube-scheduler的作用是什么？"><a href="#12-kube-apiserver和kube-scheduler的作用是什么？" class="headerlink" title="12.kube-apiserver和kube-scheduler的作用是什么？"></a>12.<code>kube-apiserver</code>和<code>kube-scheduler</code>的作用是什么？</h1><p>​    <code>kube-apiserver</code>遵循横向扩展架构，是主节点控制面板的前端。这将公开Kubernetes主节点组件的所有API，并负责在Kubernetes节点和Kubernetes主组件之间建立通信。</p>
<p>​    <code>kube-scheduler</code>负责工作节点上工作负载的分配和管理。因此，它根据资源需求选择最合适的节点来运行未调度的pod，并跟踪资源利用率。它确保不在已满的节点上调度工作负载。</p>
<h1 id="13-kubernetes控制管理器吗？"><a href="#13-kubernetes控制管理器吗？" class="headerlink" title="13.kubernetes控制管理器吗？"></a>13.kubernetes控制管理器吗？</h1><p>​    多个控制器进程在主节点上运行，但是一起编译为单个进程运行，即Kubernetes控制器管理器。因此，Controller Manager是一个嵌入控制器并执行命名空间创建和垃圾收集的守护程序。它拥有责任并与API服务器通信以管理端点。</p>
<h1 id="14-什么是ETCD？"><a href="#14-什么是ETCD？" class="headerlink" title="14.什么是ETCD？"></a>14.什么是ETCD？</h1><p>​    Etcd是用Go编程语言编写的，是一个分布式键值存储，用于协调分布式工作。因此，Etcd存储Kubernetes集群的配置数据，表示在任何给定时间点的集群状态。</p>
<h2 id="15-Kubernetes的负载均衡器了解"><a href="#15-Kubernetes的负载均衡器了解" class="headerlink" title="15.Kubernetes的负载均衡器了解"></a>15.Kubernetes的负载均衡器了解</h2><p>​    负载均衡器是暴露服务的最常见和标准方式之一。根据工作环境使用两种类型的负载均衡器，即<em>内部负载均衡器</em>或<em>外部负载均衡器</em>。内部负载均衡器自动平衡负载并使用所需配置分配容器，而外部负载均衡器将流量从外部负载引导至后端容器。</p>
<h1 id="16-Ingress网络，它是如何工作的？"><a href="#16-Ingress网络，它是如何工作的？" class="headerlink" title="16.Ingress网络，它是如何工作的？"></a>16.Ingress网络，它是如何工作的？</h1><p>​    Ingress网络是一组规则，充当Kubernetes集群的入口点。这允许入站连接，可以将其配置为通过可访问的URL，负载平衡流量或通过提供基于名称的虚拟主机从外部提供服务。因此，Ingress是一个API对象，通常通过HTTP管理集群中服务的外部访问，是暴露服务的最有效方式。</p>
<h1 id="17-Replica-Set-和-Replication-Controller之间有什么区别？"><a href="#17-Replica-Set-和-Replication-Controller之间有什么区别？" class="headerlink" title="17.Replica Set 和 Replication Controller之间有什么区别？"></a>17.Replica Set 和 Replication Controller之间有什么区别？</h1><p>​    <code>Replica Set </code>和 <code>Replication Controller</code>几乎完全相同。它们都确保在任何给定时间运行指定数量的pod副本。不同之处在于复制pod使用的选择器。Replica Set使用基于集合的选择器，而Replication Controller使用基于权限的选择器。</p>
<ul>
<li>Equity-Based选择器：这种类型的选择器允许按标签键和值进行过滤。因此，在外行术语中，基于Equity的选择器将仅查找与标签具有完全相同短语的pod。 示例：假设您的标签键表示app = nginx，那么，使用此选择器，您只能查找标签应用程序等于nginx的那些pod。</li>
<li>Selector-Based选择器：此类型的选择器允许根据一组值过滤键。因此，换句话说，基于Selector的选择器将查找已在集合中提及其标签的pod。 示例：假设您的标签键在（nginx，NPS，Apache）中显示应用程序。然后，使用此选择器，如果您的应用程序等于任何nginx，NPS或Apache，则选择器将其视为真实结果。</li>
</ul>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s集群加入与删除</title>
    <url>/2021/08/02/k8s%E9%9B%86%E7%BE%A4%E5%8A%A0%E5%85%A5%E4%B8%8E%E5%88%A0%E9%99%A4/</url>
    <content><![CDATA[<p>k8s集群加入与删除</p>
<span id="more"></span>

<h1 id="1-添加节点"><a href="#1-添加节点" class="headerlink" title="1.添加节点"></a>1.添加节点</h1><blockquote>
<p>通过kubeadm初始化后，都会提供node加入的token:<br>默认token的有效期为24小时，当过期之后，该token就不可用了。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> master 上重新生成新的 token</span></span><br><span class="line">[root@k8s-master ~]# kubeadm token create --print-join-command</span><br><span class="line">kubeadm join 192.168.81.57:6443 --token xv27mz.zx9qvxzr1n9ver8b     --discovery-token-ca-cert-hash sha256:e79022dddd20ebaa3304fe62856393cb58a5b5b6e42e51333224e1841bbf49eb </span><br><span class="line">[root@k8s-master ~]# kubeadm token list</span><br><span class="line">TOKEN                     TTL         EXPIRES                     USAGES                   DESCRIPTION                                                EXTRA GROUPS</span><br><span class="line">xv27mz.zx9qvxzr1n9ver8b   23h         2021-06-17T09:26:38+08:00   authentication,signing   &lt;none&gt;                                                     system:bootstrappers:kubeadm:default-node-token</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 新节点运行token</span><br><span class="line">[root@k8s-node2 ~]# kubeadm join 192.168.81.57:6443 --token xv27mz.zx9qvxzr1n9ver8b     --discovery-token-ca-cert-hash sha256:e79022dddd20ebaa3304fe62856393cb58a5b5b6e42e51333224e1841bbf49eb </span><br></pre></td></tr></table></figure>


<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> master 查看新节点的是否加入</span></span><br><span class="line">[root@k8s-master ~]# kubectl get node </span><br><span class="line">NAME         STATUS     ROLES                  AGE   VERSION</span><br><span class="line">k8s-master   Ready      control-plane,master   70d   v1.20.0</span><br><span class="line">k8s-node1    Ready      &lt;none&gt;                 70d   v1.20.0</span><br><span class="line">k8s-node2    NotReady   &lt;none&gt;                 3s    v1.20.0</span><br><span class="line">[root@k8s-master ~]# systemctl restart kubelet </span><br><span class="line">[root@k8s-master ~]# kubectl get node </span><br><span class="line">NAME         STATUS   ROLES                  AGE   VERSION</span><br><span class="line">k8s-master   Ready    control-plane,master   70d   v1.20.0</span><br><span class="line">k8s-node1    Ready    &lt;none&gt;                 70d   v1.20.0</span><br><span class="line">k8s-node2    Ready    &lt;none&gt;                 12s   v1.20.0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<blockquote>
<p>node节点重新加入集群操作【node节点操作】</p>
</blockquote>
<p>node节点要重新加入集群，需要重置集群状态，命令：kubeadm reset，回车后输入y即可</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubeadm reset</span><br></pre></td></tr></table></figure>
<p>重新加入集群</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubeadm join 192.168.81.57:6443 --token xv27mz.zx9qvxzr1n9ver8b     --discovery-token-ca-cert-hash sha256:e79022dddd20ebaa3304fe62856393cb58a5b5b6e42e51333224e1841bbf49eb </span><br></pre></td></tr></table></figure>



<h1 id="2-移除节点"><a href="#2-移除节点" class="headerlink" title="2.移除节点"></a>2.移除节点</h1><blockquote>
<p>k8s集群 移除节点操作</p>
</blockquote>
<p>1.确认需要移除的节点上面没有部署我们所需要的资源</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get pod -A -o wide |grep -w &quot;node名&quot; </span><br></pre></td></tr></table></figure>
<p>2.设置该节点为不可调度(不分配新的资源到该节点上) (drain命令已经会自动把node设置为不可调度，所以可以省略执行cordon命令)</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl cordon node</span><br></pre></td></tr></table></figure>

<p>3.确认完成后，先排空节点上的pod(每个节点上面都会运行一些系统自带的pod) (daemonset不会被排出节点)</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl drain node --ignore-daemonsets --force</span><br></pre></td></tr></table></figure>

<p>4.排空pod之后，便可以删除节点了</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl delete node node名</span><br></pre></td></tr></table></figure>



<p>参考链接：<a href="https://blog.csdn.net/yexusanye/article/details/117947399">https://blog.csdn.net/yexusanye/</a></p>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes常见运维技巧</title>
    <url>/2021/07/20/Kubernetes%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<p>Kubernetes常见运维技巧</p>
<span id="more"></span>

<h2 id="1、Node的隔离和恢复"><a href="#1、Node的隔离和恢复" class="headerlink" title="1、Node的隔离和恢复"></a><strong>1、Node的隔离和恢复</strong></h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Node</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-minion1</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">kubernetes.io/hostname:</span> <span class="string">kubernetes-minion1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">unschedulable:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>然后，通过kubectl replace命令完成对Node状态的修改：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl replace -f unschedule_node.yaml</span></span><br><span class="line">nodes/kubernetes-minion1</span><br></pre></td></tr></table></figure>

<p>查看Node的状态，可以观察到在Node的状态中增加了一项SchedulingDisabled：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get nodes</span></span><br><span class="line">NAME                 LABELS                                      STATUS</span><br><span class="line">kubernetes-minion1   kubernetes.io/hostname=kubernetes-minion1   Ready, SchedulingDisabled</span><br></pre></td></tr></table></figure>



<p>对于后续创建的Pod，系统将不会再向该Node进行调度。</p>
<p>另一种方法是不使用配置文件，直接使用kubectl patch命令完成：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl patch node kubernetes-minion1 -p <span class="string">&#x27;&#123;＂spec＂:&#123;＂unschedulable＂:true&#125;&#125;&#x27;</span></span></span><br></pre></td></tr></table></figure>



<p>需要注意的是，将某个Node脱离调度范围时，在其上运行的Pod并不会自动停止，管理员需要手动停止在该Node上运行的Pod。</p>
<p>同样，如果需要将某个Node重新纳入集群调度范围，则将unschedulable设置为false，再次执行kubectl replace或kubectl patch命令就能恢复系统对该Node的调度。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl cordon node-01	<span class="comment"># 设置为不可调度</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl uncordon node-01	<span class="comment"># 取消不可调度</span></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl drain ek8s-node-1 --ignore-daemonsets <span class="comment"># 驱逐节点上 Pod</span></span></span><br></pre></td></tr></table></figure>



<h2 id="2、Node的扩容"><a href="#2、Node的扩容" class="headerlink" title="2、Node的扩容"></a><strong>2、Node的扩容</strong></h2><p>​    在实际生产系统中会经常遇到服务器容量不足的情况，这时就需要购买新的服务器，然后将应用系统进行水平扩展来完成对系统的扩容。<br>​    在Kubernetes集群中，对于一个新Node的加入是非常简单的。可以在Node节点上安装Docker、Kubelet和kube-proxy服务，然后将Kubelet和kube-proxy的启动参数中的Master URL指定为当前Kubernetes集群Master的地址，最后启动这些服务。基于Kubelet的自动注册机制，新的Node将会自动加入现有的Kubernetes集群中，如图1所示。</p>
<p><img src="/images/Kubernetes%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E6%8A%80%E5%B7%A7.assets/image-20210720091116835.png" alt="image-20210720091116835"></p>
<p>Kubernetes Master在接受了新Node的注册之后，会自动将其纳入当前集群的调度范围内，在之后创建容器时，就可以向新的Node进行调度了。</p>
<p>通过这种机制，Kubernetes实现了集群的扩容。</p>
<h2 id="3、Pod动态扩容和缩放"><a href="#3、Pod动态扩容和缩放" class="headerlink" title="3、Pod动态扩容和缩放"></a><strong>3、Pod动态扩容和缩放</strong></h2><p>在实际生产系统中，我们经常会遇到某个服务需要扩容的场景，也可能会遇到由于资源紧张或者工作负载降低而需要减少服务实例数的场景。此时我们可以利用命令kubectl scale rc来完成这些任务。以redis-slave RC为例，已定义的最初副本数量为2，通过执行下面的命令将redis-slave RC控制的Pod副本数量从初始的2更新为3：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl scale rc redis-slave --replicas=3</span></span><br><span class="line">scaled</span><br></pre></td></tr></table></figure>



<p>执行kubectl get pods命令来验证Pod的副本数量增加到3：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pods</span></span><br><span class="line">NAME                   READY     STATUS    RESTARTS   AGE</span><br><span class="line">redis-slave-4na2n    1/1       Running   0          1h</span><br><span class="line">redis-slave-92u3k    1/1       Running   0          1h</span><br><span class="line">redis-slave-palab    1/1       Running   0          2m</span><br></pre></td></tr></table></figure>



<p>将–replicas设置为比当前Pod副本数量更小的数字，系统将会“杀掉”一些运行中的Pod，即可实现应用集群缩容：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl scale rc redis-slave --replicas=1</span></span><br><span class="line">scaled</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pods</span></span><br><span class="line">NAME                 	READY     	STATUS    RESTARTS   AGE</span><br><span class="line">redis-slave-4na2n    1/1       	Running   0          1h</span><br></pre></td></tr></table></figure>

<h2 id="4、更新资源对象的Label"><a href="#4、更新资源对象的Label" class="headerlink" title="4、更新资源对象的Label"></a><strong>4、更新资源对象的Label</strong></h2><p>Label（标签）作为用户可灵活定义的对象属性，在已创建的对象上，仍然可以随时通过kubectl label命令对其进行增加、修改、删除等操作。</p>
<p>例如，我们要给已创建的Pod“redis-master-bobr0”添加一个标签role=backend：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ kubectl label pod redis-master-bobr0 role=backend</span><br></pre></td></tr></table></figure>



<p>查看该Pod的Label：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ kubectl get pods -Lrole</span><br><span class="line">NAME                 READY     STATUS    RESTARTS   AGE       ROLE</span><br><span class="line">redis-master-bobr0   1/1       Running   0          3m        backend</span><br></pre></td></tr></table></figure>



<p>删除一个Label，只需在命令行最后指定Label的key名并与一个减号相连即可：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl label pod redis-master-bobr0 role-</span></span><br></pre></td></tr></table></figure>



<p>修改一个Label的值，需要加上–overwrite参数：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl label pod redis-master-bobr0 role=master --overwrite</span></span><br></pre></td></tr></table></figure>

<h2 id="5、将Pod调度到指定的Node"><a href="#5、将Pod调度到指定的Node" class="headerlink" title="5、将Pod调度到指定的Node"></a><strong>5、将Pod调度到指定的Node</strong></h2><p>我们知道，Kubernetes的Scheduler服务（kube-scheduler进程）负责实现Pod的调度，整个调度过程通过执行一系列复杂的算法最终为每个Pod计算出一个最佳的目标节点，这一过程是自动完成的，我们无法知道Pod最终会被调度到哪个节点上。有时我们可能需要将Pod调度到一个指定的Node上，此时，我们可以通过Node的标签（Label）和Pod的nodeSelector属性相匹配，来达到上述目的。</p>
<p>首先，我们可以通过kubectl label命令给目标Node打上一个特定的标签，下面是此命令的完整用法：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl label nodes &lt;node-name&gt; &lt;label-key&gt;=&lt;label-value&gt;</span><br></pre></td></tr></table></figure>



<p>这里，我们为kubernetes-minion1节点打上一个zone=north的标签，表明它是“北方”的一个节点：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl label nodes kubernetes-minion1 zone=north</span></span><br><span class="line">NAME                 LABELS                                                 STATUS</span><br><span class="line">kubernetes-minion1   kubernetes.io/hostname=kubernetes-minion1,zone=north   Ready</span><br></pre></td></tr></table></figure>



<p>上述命令行操作也可以通过修改资源定义文件的方式，并执行kubectl replace -f xxx.yaml命令来完成。</p>
<p>然后，在Pod的配置文件中加入nodeSelector定义，以redis-master-controller.yaml为例：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">redis-master</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">redis-master</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">redis-master</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">redis-master</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">master</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">kubeguide/redis-master</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">6379</span></span><br><span class="line">      <span class="attr">nodeSelector:</span></span><br><span class="line">        <span class="attr">zone:</span> <span class="string">north</span></span><br></pre></td></tr></table></figure>



<p>运行kubectl create -f命令创建Pod，scheduler就会将该Pod调度到拥有zone=north标签的Node上去。</p>
<p>使用kubectl get pods -o wide命令可以验证Pod所在的Node：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubectl get pods -o wide</span></span><br><span class="line">NAME                 READY     STATUS    RESTARTS   AGE       NODE</span><br><span class="line">redis-master-f0rqj   1/1       Running   0          19s       kubernetes-minion1</span><br></pre></td></tr></table></figure>



<p>如果我们给多个Node都定义了相同的标签（例如zone=north），则scheduler将会根据调度算法从这组Node中挑选一个可用的Node进行Pod调度。</p>
<p>这种基于Node标签的调度方式灵活性很高，比如我们可以把一组Node分别贴上“开发环境”“测试验证环境”“用户验收环境”这三组标签中的一种，此时一个Kubernetes集群就承载了3个环境，这将大大提高开发效率。</p>
<p>需要注意的是，如果我们指定了Pod的nodeSelector条件，且集群中不存在包含相应标签的Node时，即使还有其他可供调度的Node，这个Pod也最终会调度失败。</p>
<h2 id="6、应用的滚动升级"><a href="#6、应用的滚动升级" class="headerlink" title="6、应用的滚动升级"></a><strong>6、应用的滚动升级</strong></h2><p>当集群中的某个服务需要升级时，我们需要停止目前与该服务相关的所有Pod，然后重新拉取镜像并启动。如果集群规模比较大，则这个工作就变成了一个挑战，而且先全部停止然后逐步升级的方式会导致较长时间的服务不可用。Kubernetes提供了rolling-update（滚动升级）功能来解决上述问题。</p>
<p>滚动升级通过执行kubectl rolling-update命令一键完成，该命令创建了一个新的RC，然后自动控制旧的RC中的Pod副本数量逐渐减少到0，同时新的RC中的Pod副本数量从0逐步增加到目标值，最终实现了Pod的升级。需要注意的是，系统要求新的RC需要与旧的RC在相同的命名空间（Namespace）内，即不能把别人的资产偷偷转移到自家名下。</p>
<p>以redis-master为例，假设当前运行的redis-master Pod是1.0版本，则现在需要升级到2.0版本。</p>
<p>创建redis-master-controller-v2.yaml的配置文件如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">redis-master-v2</span></span><br><span class="line">  <span class="attr">labels:</span>	</span><br><span class="line">    <span class="attr">name:</span> <span class="string">redis-master</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">v2</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">redis-master</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">v2</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">redis-master</span></span><br><span class="line">        <span class="attr">version:</span> <span class="string">v2</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">master</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">kubeguide/redis-master:2.0</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">6379</span></span><br></pre></td></tr></table></figure>



<p>在配置文件中有几处需要注意：<br>（1）RC的名字（name）不能与旧的RC的名字相同；<br>（2）在selector中应至少有一个Label与旧的RC的Label不同，以标识其为新的RC。</p>
<p>本例中新增了一个名为version的Label，以与旧的RC进行区分。</p>
<p>运行kubectl rolling-update命令完成Pod的滚动升级：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl rolling-update redis-master -f redis-master-controller-v2.yaml</span></span><br></pre></td></tr></table></figure>



<p>Kubectl的执行过程如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Creating redis-master-v2</span><br><span class="line">At beginning of loop: redis-master replicas: 2, redis-master-v2 replicas: 1</span><br><span class="line">Updating redis-master replicas: 2, redis-master-v2 replicas: 1</span><br><span class="line">At end of loop: redis-master replicas: 2, redis-master-v2 replicas: 1</span><br><span class="line">At beginning of loop: redis-master replicas: 1, redis-master-v2 replicas: 2</span><br><span class="line">Updating redis-master replicas: 1, redis-master-v2 replicas: 2</span><br><span class="line">At end of loop: redis-master replicas: 1, redis-master-v2 replicas: 2</span><br><span class="line">At beginning of loop: redis-master replicas: 0, redis-master-v2 replicas: 3</span><br><span class="line">Updating redis-master replicas: 0, redis-master-v2 replicas: 3</span><br><span class="line">At end of loop: redis-master replicas: 0, redis-master-v2 replicas: 3</span><br><span class="line">Update succeeded. Deleting redis-master</span><br><span class="line">redis-master-v2</span><br></pre></td></tr></table></figure>



<p>等所有新的Pod启动完成后，旧的Pod也被全部销毁，这样就完成了容器集群的更新。</p>
<p>另一种方法是不使用配置文件，直接用kubectl rolling-update命令，加上–image参数指定新版镜像名称来完成Pod的滚动升级：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl rolling-update redis-master --image=redis-master:2.0</span></span><br></pre></td></tr></table></figure>



<p>与使用配置文件的方式不同，执行的结果是旧的RC被删除，新的RC仍将使用旧的RC的名字。</p>
<p>Kubectl的执行过程如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Creating redis-master-ea866a5d2c08588c3375b86fb253db75</span><br><span class="line">At beginning of loop: redis-master replicas: 2, redis-master-ea866a5d2c08588c 3375b86fb253db75 replicas: 1</span><br><span class="line">Updating redis-master replicas: 2, redis-master-ea866a5d2c08588c3375b86fb253db 75 replicas: 1</span><br><span class="line">At end of loop: redis-master replicas: 2, redis-master-ea866a5d2c08588c3375b86fb 253db75 replicas: 1</span><br><span class="line">At beginning of loop: redis-master replicas: 1, redis-master-ea866a5d2c08588c 3375b86fb253db75 replicas: 2</span><br><span class="line">Updating redis-master replicas: 1, redis-master-ea866a5d2c08588c3375b86fb 253db75 replicas: 2</span><br><span class="line">At end of loop: redis-master replicas: 1, redis-master-ea866a5d2c08588c3375b86fb 253db75 replicas: 2</span><br><span class="line">At beginning of loop: redis-master replicas: 0, redis-master-ea866a5d2c08588c 3375b86fb253db75 replicas: 3</span><br><span class="line">Updating redis-master replicas: 0, redis-master-ea866a5d2c08588c3375b86fb253db 75 replicas: 3</span><br><span class="line">At end of loop: redis-master replicas: 0, redis-master-ea866a5d2c08588c3375b86fb 253db75 replicas: 3</span><br><span class="line">Update succeeded. Deleting old controller: redis-master</span><br><span class="line">Renaming redis-master-ea866a5d2c08588c3375b86fb253db75 to redis-master</span><br><span class="line">redis-master</span><br></pre></td></tr></table></figure>



<p>可以看到，Kubectl通过新建一个新版本Pod，停掉一个旧版本Pod，逐步迭代来完成整个RC的更新。</p>
<p>更新完成后，查看RC：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get rc</span>	</span><br><span class="line">CONTROLLER     CONTAINER(S)   IMAGE(S)            SELECTOR        REPLICAS</span><br><span class="line">redis-master   master         kubeguide/redis-master:2.0              deployment= ea866a5d2c08588c3375b86fb253db75,name=redis-master,version=v1   3</span><br></pre></td></tr></table></figure>



<p>可以看到，Kubectl给RC增加了一个key为“deployment”的Label（这个key的名字可通过–deployment-label-key参数进行修改），Label的值是RC的内容进行Hash计算后的值，相当于签名，这样就能很方便地比较RC里的Image名字及其他信息是否发生了变化，它的具体作用可以参见第6章的源码分析。</p>
<p>如果在更新过程中发现配置有误，则用户可以中断更新操作，并通过执行Kubectl rolling-update –rollback完成Pod版本的回滚：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl rolling-update redis-master --image=kubeguide/redis-master:2.0 --rollback</span></span><br><span class="line">Found existing update in progress (redis-master-fefd9752aa5883ca4d53013a7b 583967), resuming.</span><br><span class="line">Found desired replicas.Continuing update with existing controller redis-master.</span><br><span class="line">At beginning of loop: redis-master-fefd9752aa5883ca4d53013a7b583967 replicas: 0, redis-master replicas: 3</span><br><span class="line">Updating redis-master-fefd9752aa5883ca4d53013a7b583967 replicas: 0, redis-master replicas: 3</span><br><span class="line">At end of loop: redis-master-fefd9752aa5883ca4d53013a7b583967 replicas: 0, redis-master replicas: 3</span><br><span class="line">Update succeeded. Deleting redis-master-fefd9752aa5883ca4d53013a7b583967</span><br><span class="line">redis-master</span><br></pre></td></tr></table></figure>



<p>到此，可以看到Pod恢复到更新前的版本了。</p>
<h2 id="7、Kubernetes集群高可用方案"><a href="#7、Kubernetes集群高可用方案" class="headerlink" title="7、Kubernetes集群高可用方案"></a><strong>7、Kubernetes集群高可用方案</strong></h2><p>Kubernetes作为容器应用的管理中心，通过对Pod的数量进行监控，并且根据主机或容器失效的状态将新的Pod调度到其他Node上，实现了应用层的高可用性。针对Kubernetes集群，高可用性还应包含以下两个层面的考虑：etcd数据存储的高可用性和Kubernetes Master组件的高可用性。</p>
<p><strong>7.1 etcd高可用性方案</strong></p>
<p>etcd在整个Kubernetes集群中处于中心数据库的地位，为保证Kubernetes集群的高可用性，首先需要保证数据库不是单故障点。一方面，etcd需要以集群的方式进行部署，以实现etcd数据存储的冗余、备份与高可用性；另一方面，etcd存储的数据本身也应考虑使用可靠的存储设备。</p>
<p>etcd集群的部署可以使用静态配置，也可以通过etcd提供的REST API在运行时动态添加、修改或删除集群中的成员。本节将对etcd集群的静态配置进行说明。关于动态修改的操作方法请参考etcd官方文档的说明。</p>
<p>首先，规划一个至少3台服务器（节点）的etcd集群，在每台服务器上安装好etcd。</p>
<p>部署一个由3台服务器组成的etcd集群，其配置如表1所示，其集群部署实例如图2所示。<br>表1 etcd集群的配置</p>
<p><img src="/images/Kubernetes%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E6%8A%80%E5%B7%A7.assets/image-20210720091449537.png" alt="image-20210720091449537"></p>
<p>然后修改每台服务器上etcd的配置文件/etc/etcd/etcd.conf。</p>
<p>以etcd1为创建集群的实例，需要将其ETCD_INITIAL_CLUSTER_STATE设置为“new”。etcd1的完整配置如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># [member]</span></span><br><span class="line"><span class="string">ETCD_NAME=etcd1</span>            <span class="comment">#etcd实例名称</span></span><br><span class="line"><span class="string">ETCD_DATA_DIR=＂/var/lib/etcd/etcd1＂</span>   <span class="comment">#etcd数据保存目录</span></span><br><span class="line"><span class="string">ETCD_LISTEN_PEER_URLS=＂http://10.0.0.1:2380＂</span>   <span class="comment">#集群内部通信使用的URL</span></span><br><span class="line"><span class="string">ETCD_LISTEN_CLIENT_URLS=＂http://10.0.0.1:2379＂</span>   <span class="comment">#供外部客户端使用的URL</span></span><br><span class="line"><span class="string">……</span></span><br><span class="line"><span class="comment">#[cluster]</span></span><br><span class="line"><span class="string">ETCD_INITIAL_ADVERTISE_PEER_URLS=＂http://10.0.0.1:2380＂</span>   <span class="comment">#广播给集群内其他成员使用的URL</span></span><br><span class="line"><span class="string">ETCD_INITIAL_CLUSTER=＂etcd1=http://10.0.0.1:2380,etcd2=http://10.0.0.2:2380,</span> <span class="string">etcd3=http://10.0.0.3:2380＂</span>     <span class="comment">#初始集群成员列表</span></span><br><span class="line"><span class="string">ETCD_INITIAL_CLUSTER_STATE=＂new＂</span>     <span class="comment">#初始集群状态，new为新建集群</span></span><br><span class="line"><span class="string">ETCD_INITIAL_CLUSTER_TOKEN=＂etcd-cluster＂</span>   <span class="comment">#集群名称</span></span><br><span class="line"><span class="string">ETCD_ADVERTISE_CLIENT_URLS=＂http://10.0.0.1:2379＂</span>   <span class="comment">#广播给外部客户端使用的URL</span></span><br></pre></td></tr></table></figure>



<p>启动etcd1服务器上的etcd服务：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> systemctl restart etcd</span></span><br></pre></td></tr></table></figure>



<p>启动完成后，就创建了一个名为etcd-cluster的集群。</p>
<p>etcd2和etcd3为加入etcd-cluster集群的实例，需要将其ETCD_INITIAL_CLUSTER_STATE设置为“exist”。etcd2的完整配置如下（etcd3的配置略）：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># [member]</span></span><br><span class="line"><span class="string">ETCD_NAME=etcd2</span>            <span class="comment">#etcd实例名称</span></span><br><span class="line"><span class="string">ETCD_DATA_DIR=＂/var/lib/etcd/etcd2＂</span>   <span class="comment">#etcd数据保存目录</span></span><br><span class="line"><span class="string">ETCD_LISTEN_PEER_URLS=＂http://10.0.0.2:2380＂</span>   <span class="comment">#集群内部通信使用的URL</span></span><br><span class="line"><span class="string">ETCD_LISTEN_CLIENT_URLS=＂http://10.0.0.2:2379＂</span>   <span class="comment">#供外部客户端使用的URL</span></span><br><span class="line"><span class="string">……</span></span><br><span class="line"><span class="comment">#[cluster]</span></span><br><span class="line"><span class="string">ETCD_INITIAL_ADVERTISE_PEER_URLS=＂http://10.0.0.2:2380＂</span>   <span class="comment">#广播给集群内其他成员使用的URL</span></span><br><span class="line"><span class="string">ETCD_INITIAL_CLUSTER=＂etcd1=http://10.0.0.1:2380,etcd2=http://10.0.0.2:2380,etcd3=http://10.0.0.3:2380＂</span>     <span class="comment">#初始集群成员列表</span></span><br><span class="line"><span class="string">ETCD_INITIAL_CLUSTER_STATE=＂exist＂</span>       <span class="comment"># existing表示加入已存在的集群</span></span><br><span class="line"><span class="string">ETCD_INITIAL_CLUSTER_TOKEN=＂etcd-cluster＂</span>   <span class="comment">#集群名称</span></span><br><span class="line"><span class="string">ETCD_ADVERTISE_CLIENT_URLS=＂http://10.0.0.2:2379＂</span>   <span class="comment">#广播给外部客户端使用的URL</span></span><br></pre></td></tr></table></figure>



<p>启动etcd2和etcd3服务器上的etcd服务：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> systemctl restart etcd</span></span><br></pre></td></tr></table></figure>



<p>启动完成后，在任意etcd节点执行etcdctl cluster-health命令来查询集群的运行状态：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> etcdctl cluster-health</span></span><br><span class="line">cluster is healthy</span><br><span class="line">member ce2a822cea30bfca is healthy</span><br><span class="line">member acda82ba1cf790fc is healthy</span><br><span class="line">member eba209cd0012cd2 is healthy</span><br></pre></td></tr></table></figure>



<p>在任意etcd节点上执行etcdctl member list命令来查询集群的成员列表：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> etcdctl member list</span></span><br><span class="line">ce2a822cea30bfca: name=default peerURLs=http://10.0.0.1:2380,http://10.0.0.1: 7001 clientURLs=http://10.0.0.1:2379,http://10.0.0.1:4001</span><br><span class="line">acda82ba1cf790fc: name=default peerURLs=http://10.0.0.2:2380,http://10.0.0.2: 7001 clientURLs=http://10.0.0.2:2379,http://10.0.0.2:4001</span><br><span class="line">eba209cd40012cd2: name=default peerURLs=http://10.0.0.3:2380,http://10.0.0.3: 7001 clientURLs=http://10.0.0.3:2379,http://10.0.0.3:4001</span><br></pre></td></tr></table></figure>



<p>至此，一个etcd集群就创建成功了。</p>
<p>以kube-apiserver为例，将访问etcd集群的参数设置为：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">--etcd-servers=http://10.0.0.1:4001,http://10.0.0.2:4001,http://10.0.0.3:4001</span><br></pre></td></tr></table></figure>



<p>在etcd集群成功启动之后，如果需要对集群成员进行修改，则请参考官方文档的详细说明：点击此处6</p>
<p>对于etcd中需要保存的数据的可靠性，可以考虑使用RAID磁盘阵列、高性能存储设备、NFS网络文件系统，或者使用云服务商提供的网盘系统等来实现。</p>
<p><strong>7.2 Kubernetes Master组件的高可用性方案</strong></p>
<p>在Kubernetes体系中，Master服务扮演着总控中心的角色，主要的三个服务kube-apiserver、kube-controller-mansger和kube-scheduler通过不断与工作节点上的Kubelet和kube-proxy进行通信来维护整个集群的健康工作状态。如果Master的服务无法访问到某个Node，则会将该Node标记为不可用，不再向其调度新建的Pod。但对Master自身则需要进行额外的监控，使Master不成为集群的单故障点，所以对Master服务也需要进行高可用方式的部署。</p>
<p>以Master的kube-apiserver、kube-controller-mansger和kube-scheduler三个服务作为一个部署单元，类似于etcd集群的典型部署配置。使用至少三台服务器安装Master服务，并且使用Active-Standby-Standby模式，保证任何时候总有一套Master能够正常工作。</p>
<p>所有工作节点上的Kubelet和kube-proxy服务则需要访问Master集群的统一访问入口地址，例如可以使用pacemaker等工具来实现。图3展示了一种典型的部署方式。</p>
<p><img src="/images/Kubernetes%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E6%8A%80%E5%B7%A7.assets/image-20210720091554069.png" alt="image-20210720110224277"></p>
<center>图3 Kubernetes Master高可用部署架构</center>

]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>k8s常见总结2</title>
    <url>/2021/07/17/k8s%E5%B8%B8%E8%A7%81%E6%80%BB%E7%BB%932/</url>
    <content><![CDATA[<p>k8s常见总结2</p>
<span id="more"></span>

<h3 id="1-k8s是什么？"><a href="#1-k8s是什么？" class="headerlink" title="1.k8s是什么？"></a>1.k8s是什么？</h3><p>Kubenetes是一个针对容器应用，进行自动部署，弹性伸缩和管理的开源系统。主要功能是生产环境中的容器编排。</p>
<h3 id="2-容器和主机部署应用的区别是什么？"><a href="#2-容器和主机部署应用的区别是什么？" class="headerlink" title="2.容器和主机部署应用的区别是什么？"></a>2.容器和主机部署应用的区别是什么？</h3><p>​    容器的中心思想就是秒级启动；一次封装、到处运行；这是主机部署应用无法达到的效果，但同时也更应该注重容器的数据持久化问题。另外，容器部署可以将各个服务进行隔离，互不影响，这也是容器的另一个核心概念。</p>
<h3 id="3-K8s架构的组成是什么"><a href="#3-K8s架构的组成是什么" class="headerlink" title="3.K8s架构的组成是什么"></a>3.K8s架构的组成是什么</h3><p><img src="/images/k8s%E5%B8%B8%E8%A7%81%E6%80%BB%E7%BB%932.assets/K8S%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="K8S架构图"></p>
<ul>
<li>主节点主要用于暴露API，调度部署和节点的管理；</li>
<li>计算节点运行一个容器运行环境，一般是docker环境（类似docker环境的还有rkt），同时运行一个K8s的代理（kubelet）用于和master通信。计算节点也会运行一些额外的组件，像记录日志，节点监控，服务发现等等。计算节点是k8s集群中真正工作的节点。</li>
</ul>
<p>Master节点：</p>
<ul>
<li>Kubectl：客户端命令行工具，作为整个K8s集群的操作入口；</li>
<li>Api Server：在K8s架构中承担的是“桥梁”的角色，作为资源操作的唯一入口，它提供了认证、授权、访问控制、API注册和发现等机制。客户端与k8s群集及K8s内部组件的通信，都要通过Api Server这个组件；</li>
<li>Controller-manager：负责维护群集的状态，比如故障检测、自动扩展、滚动更新等；</li>
<li>Scheduler：负责资源的调度，按照预定的调度策略将pod调度到相应的node节点上；</li>
<li>Etcd：担任数据中心的角色，保存了整个群集的状态；</li>
</ul>
<p>Node节点：</p>
<ul>
<li>Kubelet：负责维护容器的生命周期，同时也负责Volume和网络的管理，一般运行在所有的节点，是Node节点的代理，当Scheduler确定某个node上运行pod之后，会将pod的具体信息（image，volume）等发送给该节点的kubelet，kubelet根据这些信息创建和运行容器，并向master返回运行状态。（自动修复功能：如果某个节点中的容器宕机，它会尝试重启该容器，若重启无效，则会将该pod杀死，然后重新创建一个容器）；</li>
<li>Kube-proxy：Service在逻辑上代表了后端的多个pod。负责为Service提供cluster内部的服务发现和负载均衡（外界通过Service访问pod提供的服务时，Service接收到的请求后就是通过kube-proxy来转发到pod上的）；</li>
<li>container-runtime：是负责管理运行容器的软件，比如docker</li>
<li>Pod：是k8s集群里面最小的单位。每个pod里边可以运行一个或多个container（容器），如果一个pod中有两个container，那么container的USR（用户）、MNT（挂载点）、PID（进程号）是相互隔离的，UTS（主机名和域名）、IPC（消息队列）、NET（网络栈）是相互共享的。</li>
</ul>
<h3 id="4-kubenetes针对pod资源对象的健康监测机制。"><a href="#4-kubenetes针对pod资源对象的健康监测机制。" class="headerlink" title="4.kubenetes针对pod资源对象的健康监测机制。"></a>4.kubenetes针对pod资源对象的健康监测机制。</h3><p>K8s中对于pod资源对象的健康状态检测，提供了三类probe（探针）来执行对pod的健康监测：</p>
<p>1） livenessProbe探针</p>
<p>可以根据用户自定义规则来判定pod是否健康，如果livenessProbe探针探测到容器不健康，则kubelet会根据其重启策略来决定是否重启，初始探测状态为健康状态直到探测失败。如果一个容器不包含livenessProbe探针，则kubelet会认为容器的livenessProbe探针的返回值永远成功。</p>
<p>2） ReadinessProbe探针</p>
<p>同样是可以根据用户自定义规则来判断pod是否健康，如果探测失败，控制器会将此pod从对应service的endpoint列表中移除，从此不再将任何请求调度到此Pod上，直到下次探测成功。初始探测为失败状态，直到探测成功后，将pod加入到service的endpoint列表中。</p>
<p>3） startupProbe探针</p>
<p>启动检查机制，应用一些启动缓慢的业务，避免业务长时间启动而被上面两类探针kill掉，这个问题也可以换另一种方式解决，就是定义上面两类探针机制时，初始化时间定义的长一些即可。</p>
<p>探针检查支持以下参数设置：</p>
<ul>
<li>initialDelaySeconds：初始第一次探测间隔，用于应用启动的时间，防止应用还没启动而健康检查失败</li>
<li>periodSeconds：检查间隔，多久执行probe检查，默认为10s；</li>
<li>timeoutSeconds：检查超时时长，探测应用timeout后为失败；</li>
<li>successThreshold：成功探测阈值，表示探测多少次为健康正常，默认探测1次。</li>
</ul>
<p>探针支持分探测方案：</p>
<p>1）.通过执行命令的方式来检查服务是否正常，比如使用cat命令查看pod中的某个重要配置文件是否存在，若存在，则表示pod健康。反之异常。</p>
<p>Exec探测方式的yaml文件语法如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span>  </span><br><span class="line">  <span class="attr">containers:</span>  </span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness</span>  </span><br><span class="line">    <span class="attr">image:</span> <span class="string">k8s.gcr.io/busybox</span>  </span><br><span class="line">    <span class="attr">args:</span>  </span><br><span class="line">    <span class="bullet">-</span> <span class="string">/bin/sh</span>  </span><br><span class="line">    <span class="bullet">-</span> <span class="string">-c</span>  </span><br><span class="line">    <span class="bullet">-</span> <span class="string">touch</span> <span class="string">/tmp/healthy;</span> <span class="string">sleep</span> <span class="number">30</span><span class="string">;</span> <span class="string">rm</span> <span class="string">-rf</span> <span class="string">/tmp/healthy;</span> <span class="string">sleep</span> <span class="number">600</span>  </span><br><span class="line">    <span class="attr">livenessProbe:</span>         <span class="comment">#选择livenessProbe的探测机制  </span></span><br><span class="line">      <span class="attr">exec:</span>                      <span class="comment">#执行以下命令  </span></span><br><span class="line">        <span class="attr">command:</span>  </span><br><span class="line">        <span class="bullet">-</span> <span class="string">cat</span>  </span><br><span class="line">        <span class="bullet">-</span> <span class="string">/tmp/healthy</span>  </span><br><span class="line">      <span class="attr">initialDelaySeconds:</span> <span class="number">5</span>          <span class="comment">#在容器运行五秒后开始探测  </span></span><br><span class="line">      <span class="attr">periodSeconds:</span> <span class="number">5</span>               <span class="comment">#每次探测的时间间隔为5秒  </span></span><br></pre></td></tr></table></figure>

<p>在上面的配置文件中，探测机制为在容器运行5秒后，每隔五秒探测一次，如果cat命令返回的值为“0”，则表示健康，如果为非0，则表示异常。</p>
<p>2）Httpget： 通过发送http/htps请求检查服务是否正常，返回的状态码为200-399则表示容器健康（注http get类似于命令curl -I）。</p>
<p>Httpget探测方式的yaml文件语法如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span>  </span><br><span class="line">  <span class="attr">containers:</span>  </span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">liveness</span>  </span><br><span class="line">    <span class="attr">image:</span> <span class="string">k8s.gcr.io/liveness</span>  </span><br><span class="line">    <span class="attr">livenessProbe:</span>              <span class="comment">#采用livenessProbe机制探测  </span></span><br><span class="line">      <span class="attr">httpGet:</span>                  <span class="comment">#采用httpget的方式  </span></span><br><span class="line">    <span class="string">scheme:HTTP</span>         <span class="comment">#指定协议，也支持https  </span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/healthz</span>          <span class="comment">#检测是否可以访问到网页根目录下的healthz网页文件  </span></span><br><span class="line">        <span class="attr">port:</span> <span class="number">8080</span>              <span class="comment">#监听端口是8080  </span></span><br><span class="line">      <span class="attr">initialDelaySeconds:</span> <span class="number">3</span>     <span class="comment">#容器运行3秒后开始探测  </span></span><br><span class="line">      <span class="attr">periodSeconds:</span> <span class="number">3</span>                <span class="comment">#探测频率为3秒  </span></span><br></pre></td></tr></table></figure>

<p>上述配置文件中，探测方式为项容器发送HTTP GET请求，请求的是8080端口下的healthz文件，返回任何大于或等于200且小于400的状态码表示成功。任何其他代码表示异常。</p>
<p>3）tcpSocket： 通过容器的IP和Port执行TCP检查，如果能够建立TCP连接，则表明容器健康，这种方式与HTTPget的探测机制有些类似，tcpsocket健康检查适用于TCP业务。</p>
<p>tcpSocket探测方式的yaml文件语法如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span>  </span><br><span class="line">  <span class="attr">containers:</span>  </span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">goproxy</span>  </span><br><span class="line">    <span class="attr">image:</span> <span class="string">k8s.gcr.io/goproxy:0.1</span>  </span><br><span class="line">    <span class="attr">ports:</span>  </span><br><span class="line"><span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">8080</span>  </span><br><span class="line"><span class="comment">#这里两种探测机制都用上了，都是为了和容器的8080端口建立TCP连接  </span></span><br><span class="line">    <span class="attr">readinessProbe:</span>  </span><br><span class="line">      <span class="attr">tcpSocket:</span>  </span><br><span class="line">        <span class="attr">port:</span> <span class="number">8080</span>  </span><br><span class="line">      <span class="attr">initialDelaySeconds:</span> <span class="number">5</span>  </span><br><span class="line">      <span class="attr">periodSeconds:</span> <span class="number">10</span>  </span><br><span class="line">    <span class="attr">livenessProbe:</span>  </span><br><span class="line">      <span class="attr">tcpSocket:</span>  </span><br><span class="line">        <span class="attr">port:</span> <span class="number">8080</span>  </span><br><span class="line">      <span class="attr">initialDelaySeconds:</span> <span class="number">15</span>  </span><br><span class="line">      <span class="attr">periodSeconds:</span> <span class="number">20</span>  </span><br></pre></td></tr></table></figure>

<p>在上述的yaml配置文件中，两类探针都使用了，在容器启动5秒后，kubelet将发送第一个readinessProbe探针，这将连接容器的8080端口，如果探测成功，则该pod为健康，十秒后，kubelet将进行第二次连接。</p>
<p>除了readinessProbe探针外，在容器启动15秒后，kubelet将发送第一个livenessProbe探针，仍然尝试连接容器的8080端口，如果连接失败，则重启容器。</p>
<p>探针探测的结果有以下三种可能：</p>
<ul>
<li>Success：Container通过了检查；</li>
<li>Failure：Container没有通过检查；</li>
<li>Unknown：没有执行检查，因此不采取任何措施（通常是我们没有定义探针检测，默认为成功）。</li>
</ul>
<h3 id="5-如何控制滚动更新过程"><a href="#5-如何控制滚动更新过程" class="headerlink" title="5.如何控制滚动更新过程"></a><strong>5.如何控制滚动更新过程</strong></h3><p>可以通过下面的命令查看到更新时可以控制的参数：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl explain deploy.spec.strategy.rollingUpdate </span><br></pre></td></tr></table></figure>

<p>maxSurge：　此参数控制滚动更新过程，副本总数超过预期pod数量的上限。可以是百分比，也可以是具体的值。默认为1。</p>
<p>（上述参数的作用就是在更新过程中，值若为3，那么不管三七二一，先运行三个pod，用于替换旧的pod，以此类推）</p>
<p>maxUnavailable： 此参数控制滚动更新过程中，不可用的Pod的数量。</p>
<p>（这个值和上面的值没有任何关系，举个例子：我有十个pod，但是在更新的过程中，我允许这十个pod中最多有三个不可用，那么就将这个参数的值设置为3，在更新的过程中，只要不可用的pod数量小于或等于3，那么更新过程就不会停止）。</p>
<h3 id="6-镜像下载策略是什么"><a href="#6-镜像下载策略是什么" class="headerlink" title="6.镜像下载策略是什么"></a><strong>6.镜像下载策略是什么</strong></h3><p>可通过命令“kubectl explain pod.spec.containers”来查看imagePullPolicy这行的解释。</p>
<p>K8s的镜像下载策略有三种：Always、Never、IFNotPresent；</p>
<ul>
<li>Always：镜像标签为latest时，总是从指定的仓库中获取镜像；</li>
<li>Never：禁止从仓库中下载镜像，也就是说只能使用本地镜像；</li>
<li>IfNotPresent：仅当本地没有对应镜像时，才从目标仓库中下载。</li>
<li>默认的镜像下载策略是：当镜像标签是latest时，默认策略是Always；当镜像标签是自定义时（也就是标签不是latest），那么默认策略是IfNotPresent。</li>
</ul>
<h3 id="7-image的状态有哪些"><a href="#7-image的状态有哪些" class="headerlink" title="7.image的状态有哪些"></a><strong>7.image的状态有哪些</strong></h3><ul>
<li>Running：Pod所需的容器已经被成功调度到某个节点，且已经成功运行，</li>
<li>Pending：APIserver创建了pod资源对象，并且已经存入etcd中，但它尚未被调度完成或者仍然处于仓库中下载镜像的过程</li>
<li>Unknown：APIserver无法正常获取到pod对象的状态，通常是其无法与所在工作节点的kubelet通信所致。</li>
</ul>
<h3 id="8-pod的重启策略是什么？"><a href="#8-pod的重启策略是什么？" class="headerlink" title="8.pod的重启策略是什么？"></a><strong>8.pod的重启策略是什么？</strong></h3><p>可以通过命令“kubectl explain pod.spec”查看pod的重启策略。（restartPolicy字段）</p>
<ul>
<li>Always：但凡pod对象终止就重启，此为默认策略。</li>
<li>OnFailure：仅在pod对象出现错误时才重启</li>
</ul>
<h3 id="9-K8s中部署应用版本回滚的命令"><a href="#9-K8s中部署应用版本回滚的命令" class="headerlink" title="9.K8s中部署应用版本回滚的命令"></a><strong>9.K8s中部署应用版本回滚的命令</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f httpd2-deploy1.yaml --record  </span><br><span class="line"><span class="meta">#</span><span class="bash">运行yaml文件，并记录版本信息；</span> </span><br><span class="line"></span><br><span class="line">kubectl rollout history deployment httpd-devploy1  </span><br><span class="line"><span class="meta">#</span><span class="bash">查看该deployment的历史版本</span> </span><br><span class="line"></span><br><span class="line">kubectl rollout undo deployment httpd-devploy1 --to-revision=1   </span><br><span class="line"><span class="meta">#</span><span class="bash">执行回滚操作，指定回滚到版本1</span> </span><br></pre></td></tr></table></figure>



<h3 id="10-标签和标签选择器的作用是什么？"><a href="#10-标签和标签选择器的作用是什么？" class="headerlink" title="10.标签和标签选择器的作用是什么？"></a><strong>10.标签和标签选择器的作用是什么？</strong></h3><p>标签：是当相同类型的资源对象越来越多的时候，为了更好的管理，可以按照标签将其分为一个组，为的是提升资源对象的管理效率。</p>
<p>标签选择器：就是标签的查询过滤条件。目前API支持两种标签选择器：</p>
<ul>
<li>基于等值关系的，如：“=”、“ ” “= =”  、  “！=”（注：“==”也是等于的意思，yaml文件中的matchLabels字段）；</li>
<li>基于集合的，如：in、notin、exists（yaml文件中的matchExpressions字段）；</li>
</ul>
<h3 id="11-常用的标签分类有哪些？"><a href="#11-常用的标签分类有哪些？" class="headerlink" title="11.常用的标签分类有哪些？"></a><strong>11.常用的标签分类有哪些？</strong></h3><p>标签分类是可以自定义的，但是为了能使他人可以达到一目了然的效果，一般会使用以下一些分类：</p>
<ul>
<li>版本类标签（release）：stable（稳定版）、canary（金丝雀版本，可以将其称之为测试版中的测试版）、beta（测试版）；</li>
<li>环境类标签（environment）：dev（开发）、qa（测试）、production（生产）、op（运维）；</li>
<li>应用类（app）：ui、as、pc、sc；</li>
<li>架构类（tier）：frontend（前端）、backend（后端）、cache（缓存）；</li>
<li>分区标签（partition）：customerA（客户A）、customerB（客户B）；</li>
<li>品控级别（Track）：daily（每天）、weekly（每周）</li>
</ul>
<h3 id="12-查看标签的方式。"><a href="#12-查看标签的方式。" class="headerlink" title="12.查看标签的方式。"></a><strong>12.查看标签的方式。</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get pod --show-labels  #查看pod，并且显示标签内容 </span><br><span class="line"></span><br><span class="line">kubectl get pod -L env,tier    #显示资源对象标签的值 </span><br><span class="line"></span><br><span class="line">kubectl get pod -l env,tier    #只显示符合键值资源对象的pod，而“-L”是显示所有的pod </span><br></pre></td></tr></table></figure>



<h3 id="13-添加、修改觉删除标签的命令"><a href="#13-添加、修改觉删除标签的命令" class="headerlink" title="13.添加、修改觉删除标签的命令"></a><strong>13.添加、修改觉删除标签的命令</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">对pod标签的操作</span> </span><br><span class="line">kubectl label pod label-pod abc=123   #给名为label-pod的pod添加标签 </span><br><span class="line">kubectl label pod label-pod abc=456 --overwrite   #修改名为label-pod的标签 </span><br><span class="line">kubectl label pod label-pod abc-       #删除名为label-pod的标签 </span><br><span class="line">kubectl get pod --show-labels </span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">对node节点的标签操作</span>   </span><br><span class="line">kubectl label nodes node01 disk=ssd   #给节点node01添加disk标签 </span><br><span class="line">kubectl label nodes node01 disk=sss –overwrite  #修改节点node01的标签 </span><br><span class="line">kubectl label nodes node01 disk-     #删除节点node01的disk标签 </span><br></pre></td></tr></table></figure>



<h3 id="14-DaemonSet资源对象的特性"><a href="#14-DaemonSet资源对象的特性" class="headerlink" title="14.DaemonSet资源对象的特性"></a><strong>14.DaemonSet资源对象的特性</strong></h3><p>DaemonSet这种资源对象会在每个k8s集群中的节点上运行，并且每个节点只能运行一个pod，这是它和deployment资源对象的最大也是唯一的区别。</p>
<h3 id="15-Pod的生命周期有哪些状态？"><a href="#15-Pod的生命周期有哪些状态？" class="headerlink" title="15.Pod的生命周期有哪些状态？"></a><strong>15.Pod的生命周期有哪些状态？</strong></h3><ul>
<li>Pending：表示pod已经被同意创建，正在等待kube-scheduler选择合适的节点创建，或者正在准备镜像；</li>
<li>Running：表示pod中所有的容器已经被创建，并且至少有一个容器正在运行或者是正在启动或者是正在重启；</li>
<li>Succeeded：表示所有容器已经成功终止，并且不会再启动；</li>
<li>Failed：表示pod中所有容器都是非0（不正常）状态退出；</li>
<li>Unknown：表示无法读取Pod状态，通常是kube-controller-manager无法与Pod通信。</li>
</ul>
<h3 id="16-创建一个Pod的流程是如何的？"><a href="#16-创建一个Pod的流程是如何的？" class="headerlink" title="16.创建一个Pod的流程是如何的？"></a>16.创建一个Pod的流程是如何的？</h3><p><img src="/images/k8s%E5%B8%B8%E8%A7%81%E6%80%BB%E7%BB%932.assets/%E5%88%9B%E5%BB%BApod%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="创建pod流程图"></p>
<p><img src="/images/k8s%E5%B8%B8%E8%A7%81%E6%80%BB%E7%BB%932.assets/1465170-20190403102521028-1937176408.png" alt="1465170-20190403102521028-1937176408"></p>
<ul>
<li>客户端提交Pod的配置信息（可以是yaml文件定义好的信息）到kube-apiserver；</li>
<li>Apiserver收到指令后，通知给controller-manager创建一个资源对象；</li>
<li>Controller-manager通过api-server将pod的配置信息存储到ETCD数据中心中；</li>
<li>Kube-scheduler检测到pod信息会开始调度预选，会先过滤掉不符合Pod资源配置要求的节点，然后开始调度调优，主要是挑选出更适合运行pod的节点，然后将pod的资源配置单发送到node节点上的kubelet组件上。</li>
<li>Kubelet根据scheduler发来的资源配置单运行pod，运行成功后，将pod的运行信息返回给scheduler，scheduler将返回的pod运行状况的信息存储到etcd数据中心。</li>
</ul>
<h3 id="17-删除一个Pod的流程是如何的？"><a href="#17-删除一个Pod的流程是如何的？" class="headerlink" title="17.删除一个Pod的流程是如何的？"></a>17.删除一个Pod的流程是如何的？</h3><p>Kube-apiserver会接受到用户的删除指令，默认有30秒时间等待优雅退出，超过30秒会被标记为死亡状态，此时Pod的状态Terminating，kubelet看到pod标记为Terminating就开始了关闭Pod的工作；</p>
<p>关闭流程如下：</p>
<ul>
<li>pod从service的endpoint列表中被移除；</li>
<li>如果该pod定义了一个停止前的钩子，其会在pod内部被调用，停止钩子一般定义了如何优雅的结束进程；</li>
<li>进程被发送TERM信号（kill -14）</li>
<li>当超过优雅退出的时间后，Pod中的所有进程都会被发送SIGKILL信号（kill -9）。</li>
</ul>
<h3 id="18-K8s的service是什么？"><a href="#18-K8s的service是什么？" class="headerlink" title="18.K8s的service是什么？"></a>18.K8s的service是什么？</h3><p>Pod每次重启或者重新部署，其IP地址都会产生变化，这使得pod间通信和pod与外部通信变得困难，这时候，就需要Service为pod提供一个固定的入口。</p>
<p>Service的Endpoint列表通常绑定了一组相同配置的pod，通过负载均衡的方式把外界请求分配到多个pod上。</p>
<h3 id="19-k8s如何进服务注册？"><a href="#19-k8s如何进服务注册？" class="headerlink" title="19.k8s如何进服务注册？"></a>19.k8s如何进服务注册？</h3><p>Pod启动后会加载当前环境所有Service信息，以便不同Pod根据Service名进行通信。</p>
<h3 id="20-K8s数据持久化的方式有哪些？"><a href="#20-K8s数据持久化的方式有哪些？" class="headerlink" title="20.K8s数据持久化的方式有哪些？"></a>20.K8s数据持久化的方式有哪些？</h3><p>​    <code>emptyDir:</code>emptyDir是最基础的Volume类型，用于存储临时数据的简单空目录。如果Pod设置了emptyDir类型Volume，Pod被分配到Node上时候，会创建emptyDir，只要Pod运行在Node上，emptyDir都会存在（容器挂掉不会导致emptyDir丢失数据），但是如果Pod从Node上被删除（Pod被删除，或者Pod发生迁移），emptyDir也会被删除，并且永久丢失。</p>
<p>​    <code>Hostpath:</code>将宿主机上已存在的目录或文件挂载到容器内部。类似于docker中的bind mount挂载方式。这种数据持久化方式，运用场景不多，因为它增加了pod与节点之间的耦合。</p>
<p>​    <code>PersistentVolume:</code> PersistentVolume(持久卷， 简称 PV)和Persistent VolumeClaim(持久卷声明，简称 PVC)使得K8s集群具备了存储的逻辑抽象能力，使得在配置Pod的逻辑里可以忽略对实际后台存储技术的配置，而把这项配置的工作交给PV的配置者，即集群的管理者。存储的PV和PVC的这种关系，跟计算的Node和Pod的关系是非常类似的；PV和Node是资源的提供者，根据集群的基础设施变化而变化，由K8s集群管理员配置；而PVC和Pod是资源的使用者，根据业务服务的需求变化而变化，由K8s集群的使用者即服务的管理员来配置。</p>
<hr>
<center>END</center>

<hr>
]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title>kubeadm部署k8s</title>
    <url>/2021/06/20/kubeadm%E9%83%A8%E7%BD%B2k8s/</url>
    <content><![CDATA[<p>kubeadm是官方社区推出的一个用于快速部署kubernetes集群的工具。</p>
<span id="more"></span>
<p>这个工具能通过两条指令完成一个kubernetes集群的部署：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建一个 Master 节点</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubeadm init</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将一个 Node 节点加入到当前集群中</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubeadm join &lt;Master节点的IP和端口 &gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="1-安装要求"><a href="#1-安装要求" class="headerlink" title="1. 安装要求"></a>1. 安装要求</h2><p>在开始之前，部署Kubernetes集群机器需要满足以下几个条件：</p>
<ul>
<li>一台或多台机器，操作系统 CentOS7.x-86_x64</li>
<li>硬件配置：2GB或更多RAM，2个CPU或更多CPU，硬盘30GB或更多</li>
<li>集群中所有机器之间网络互通</li>
<li>可以访问外网，需要拉取镜像</li>
<li>禁止swap分区</li>
</ul>
<h2 id="2-准备环境"><a href="#2-准备环境" class="headerlink" title="2. 准备环境"></a>2. 准备环境</h2><table>
<thead>
<tr>
<th>角色</th>
<th>IP</th>
</tr>
</thead>
<tbody><tr>
<td>k8s-master</td>
<td>192.168.81.57</td>
</tr>
<tr>
<td>k8s-node1</td>
<td>192.168.81.58</td>
</tr>
<tr>
<td>k8s-node2</td>
<td>192.168.81.59</td>
</tr>
</tbody></table>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 关闭防火墙：</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 关闭selinux：</span></span><br><span class="line">sed -i &#x27;s/enforcing/disabled/&#x27; /etc/selinux/config  # 永久</span><br><span class="line">setenforce 0  # 临时</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 关闭swap：</span></span><br><span class="line">swapoff -a  # 临时</span><br><span class="line">vim /etc/fstab  # 永久</span><br><span class="line">swapoff /dev/mapper/centos-swap</span><br><span class="line">free -h</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置主机名：</span></span><br><span class="line">hostnamectl set-hostname &lt;hostname&gt;</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在master添加hosts：</span></span><br><span class="line">cat &gt;&gt; /etc/hosts &lt;&lt; EOF</span><br><span class="line">192.168.81.57 k8s-master</span><br><span class="line">192.168.81.58 k8s-node1</span><br><span class="line">192.168.81.59 k8s-node2</span><br><span class="line">EOF</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将桥接的IPv4流量传递到iptables的链：</span></span><br><span class="line">cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line">sysctl --system  # 生效</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 时间同步：</span></span><br><span class="line">yum install ntpdate -y</span><br><span class="line">ntpdate time.windows.com</span><br></pre></td></tr></table></figure>

<h2 id="3-安装Docker-kubeadm-kubelet【所有节点】"><a href="#3-安装Docker-kubeadm-kubelet【所有节点】" class="headerlink" title="3. 安装Docker/kubeadm/kubelet【所有节点】"></a>3. 安装Docker/kubeadm/kubelet【所有节点】</h2><p>Kubernetes默认CRI（容器运行时）为Docker，因此先安装Docker。</p>
<h3 id="3-1-安装Docker"><a href="#3-1-安装Docker" class="headerlink" title="3.1 安装Docker"></a>3.1 安装Docker</h3><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">wget http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line">wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo</span><br><span class="line">yum -y install docker-ce</span><br><span class="line">systemctl <span class="built_in">enable</span> docker &amp;&amp; systemctl start docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看docker版本</span></span><br><span class="line">[root@localhost ~]<span class="comment"># docker version</span></span><br><span class="line">Client: Docker Engine - Community</span><br><span class="line"> Version:           20.10.5</span><br><span class="line"> API version:       1.41</span><br><span class="line"> Go version:        go1.13.15</span><br><span class="line"> Git commit:        55c4c88</span><br><span class="line"> Built:             Tue Mar  2 20:33:55 2021</span><br><span class="line"> OS/Arch:           linux/amd64</span><br><span class="line"> Context:           default</span><br><span class="line"> Experimental:      <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">Server: Docker Engine - Community</span><br><span class="line"> Engine:</span><br><span class="line">  Version:          20.10.5</span><br><span class="line">  API version:      1.41 (minimum version 1.12)</span><br><span class="line">  Go version:       go1.13.15</span><br><span class="line">  Git commit:       363e9a8</span><br><span class="line">  Built:            Tue Mar  2 20:32:17 2021</span><br><span class="line">  OS/Arch:          linux/amd64</span><br><span class="line">  Experimental:     <span class="literal">false</span></span><br><span class="line"> containerd:</span><br><span class="line">  Version:          1.4.4</span><br><span class="line">  GitCommit:        05f951a3781f4f2c1911b05e61c160e9c30eaa8e</span><br><span class="line"> runc:</span><br><span class="line">  Version:          1.0.0-rc93</span><br><span class="line">  GitCommit:        12644e614e25b05da6fd08a38ffa0cfe1903fdec</span><br><span class="line"> docker-init:</span><br><span class="line">  Version:          0.19.0</span><br><span class="line">  GitCommit:        de40ad0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>配置镜像下载加速器：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt; EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl restart docker</span><br><span class="line">docker info</span><br></pre></td></tr></table></figure>

<h3 id="3-2-添加阿里云YUM软件源"><a href="#3-2-添加阿里云YUM软件源" class="headerlink" title="3.2 添加阿里云YUM软件源"></a>3.2 添加阿里云YUM软件源</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="3-2-1-常用管理命令"><a href="#3-2-1-常用管理命令" class="headerlink" title="3.2.1 常用管理命令"></a>3.2.1 常用管理命令</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 命令格式：docker image COMMAND</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 指令 描述</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> ls			//列出镜像</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> build			//构建镜像来自Dockerfile</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">history</span>		//查看镜像历史</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> inspect		//显示一个或多个镜像详细信息</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> pull			//从镜像仓库拉取镜像</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> push			//推送一个镜像到镜像仓库</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> rm			//移除一个或多个镜像</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> prune			//移除没有被标记或者没有被任何容器引用的镜像</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> tag			//创建一个引用源镜像标记目标镜像</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> save			//保存一个或多个镜像到一个tar归档文件</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> load			//加载镜像来自tar归档或标准输入</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>docker save load使用</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 将有网络的镜像打包为tar文件 81.57操作</span></span><br><span class="line">[root@localhost ~]# docker save nginx -o nginx.tar</span><br><span class="line">[root@localhost ~]# ls</span><br><span class="line">anaconda-ks.cfg  nginx.tar</span><br><span class="line">[root@localhost ~]# du -sh nginx.tar </span><br><span class="line">131M	nginx.tar</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看tar包内容</span></span><br><span class="line">[root@localhost ~]# tar tvf nginx.tar </span><br><span class="line">-rw-r--r-- 0/0            7731 2021-03-11 08:21 018aec2b4f302b08b4c7274b72bede1fe56ee1f2bcaa06492e3f464e05f1a9a8.json</span><br><span class="line">drwxr-xr-x 0/0               0 2021-03-11 08:21 1f1a90348f908c579d0340f4bac7680918de1fa2f4c4fd2c2145a663d6178064/</span><br><span class="line">-rw-r--r-- 0/0               3 2021-03-11 08:21 1f1a90348f908c579d0340f4bac7680918de1fa2f4c4fd2c2145a663d6178064/VERSION</span><br><span class="line">-rw-r--r-- 0/0             482 2021-03-11 08:21 1f1a90348f908c579d0340f4bac7680918de1fa2f4c4fd2c2145a663d6178064/json</span><br><span class="line">-rw-r--r-- 0/0            4096 2021-03-11 08:21 1f1a90348f908c579d0340f4bac7680918de1fa2f4c4fd2c2145a663d6178064/layer.tar</span><br><span class="line">drwxr-xr-x 0/0               0 2021-03-11 08:21 3ed7719d733be9ef3895d3b6435ba67c07087b06aaef54a4d63ea59ca1ca5c32/</span><br><span class="line">-rw-r--r-- 0/0               3 2021-03-11 08:21 3ed7719d733be9ef3895d3b6435ba67c07087b06aaef54a4d63ea59ca1ca5c32/VERSION</span><br><span class="line">-rw-r--r-- 0/0            1682 2021-03-11 08:21 3ed7719d733be9ef3895d3b6435ba67c07087b06aaef54a4d63ea59ca1ca5c32/json</span><br><span class="line">-rw-r--r-- 0/0            7168 2021-03-11 08:21 3ed7719d733be9ef3895d3b6435ba67c07087b06aaef54a4d63ea59ca1ca5c32/layer.tar</span><br><span class="line">drwxr-xr-x 0/0               0 2021-03-11 08:21 4fc81aabdfa5c3ae98c390eccf8414520a26d6c3aa8974d5fccccf61d889aa04/</span><br><span class="line">-rw-r--r-- 0/0               3 2021-03-11 08:21 4fc81aabdfa5c3ae98c390eccf8414520a26d6c3aa8974d5fccccf61d889aa04/VERSION</span><br><span class="line">-rw-r--r-- 0/0             482 2021-03-11 08:21 4fc81aabdfa5c3ae98c390eccf8414520a26d6c3aa8974d5fccccf61d889aa04/json</span><br><span class="line">-rw-r--r-- 0/0            3584 2021-03-11 08:21 4fc81aabdfa5c3ae98c390eccf8414520a26d6c3aa8974d5fccccf61d889aa04/layer.tar</span><br><span class="line">drwxr-xr-x 0/0               0 2021-03-11 08:21 7822202c2b2274fafc6cf0d948baca257fe26ccb6858084a19ec635e81b210f3/</span><br><span class="line">-rw-r--r-- 0/0               3 2021-03-11 08:21 7822202c2b2274fafc6cf0d948baca257fe26ccb6858084a19ec635e81b210f3/VERSION</span><br><span class="line">-rw-r--r-- 0/0             482 2021-03-11 08:21 7822202c2b2274fafc6cf0d948baca257fe26ccb6858084a19ec635e81b210f3/json</span><br><span class="line">-rw-r--r-- 0/0            3072 2021-03-11 08:21 7822202c2b2274fafc6cf0d948baca257fe26ccb6858084a19ec635e81b210f3/layer.tar</span><br><span class="line">drwxr-xr-x 0/0               0 2021-03-11 08:21 8b9e24c9de24a93a1a2da83ab6830ba2ac2914fb5c3af42bc3a8c198640e1299/</span><br><span class="line">-rw-r--r-- 0/0               3 2021-03-11 08:21 8b9e24c9de24a93a1a2da83ab6830ba2ac2914fb5c3af42bc3a8c198640e1299/VERSION</span><br><span class="line">-rw-r--r-- 0/0             482 2021-03-11 08:21 8b9e24c9de24a93a1a2da83ab6830ba2ac2914fb5c3af42bc3a8c198640e1299/json</span><br><span class="line">-rw-r--r-- 0/0        64807936 2021-03-11 08:21 8b9e24c9de24a93a1a2da83ab6830ba2ac2914fb5c3af42bc3a8c198640e1299/layer.tar</span><br><span class="line">drwxr-xr-x 0/0               0 2021-03-11 08:21 e86c0242e63168af8ce7e8640b4f884c500a003fed9ccfedd98f682c5026daf4/</span><br><span class="line">-rw-r--r-- 0/0               3 2021-03-11 08:21 e86c0242e63168af8ce7e8640b4f884c500a003fed9ccfedd98f682c5026daf4/VERSION</span><br><span class="line">-rw-r--r-- 0/0             406 2021-03-11 08:21 e86c0242e63168af8ce7e8640b4f884c500a003fed9ccfedd98f682c5026daf4/json</span><br><span class="line">-rw-r--r-- 0/0        72491008 2021-03-11 08:21 e86c0242e63168af8ce7e8640b4f884c500a003fed9ccfedd98f682c5026daf4/layer.tar</span><br><span class="line">-rw-r--r-- 0/0             586 1970-01-01 08:00 manifest.json</span><br><span class="line">-rw-r--r-- 0/0              88 1970-01-01 08:00 repositories</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 传到没有网络的主机</span></span><br><span class="line">[root@localhost ~]# scp nginx.tar 192.168.81.58:/root</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 81.58操作导入tar包到本地镜像</span></span><br><span class="line">[root@localhost ~]# docker load -i  nginx.tar </span><br><span class="line"></span><br><span class="line">[root@localhost ~]# docker images </span><br><span class="line">REPOSITORY   TAG       IMAGE ID       CREATED        SIZE</span><br><span class="line">nginx        latest    018aec2b4f30   26 hours ago   133MB</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动nginx镜像映射IP</span></span><br><span class="line">[root@localhost ~]# docker run -d -p 8080:80 nginx</span><br><span class="line">38f999f57ffa1c1ab6799eab45323152564a943c00081a3f98838f5ef29fca21</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h3 id="3-3-安装kubeadm，kubelet和kubectl"><a href="#3-3-安装kubeadm，kubelet和kubectl" class="headerlink" title="3.3 安装kubeadm，kubelet和kubectl"></a>3.3 安装kubeadm，kubelet和kubectl</h3><p>由于版本更新频繁，这里指定版本号部署：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 所有节点操作</span></span><br><span class="line">yum install -y kubelet-1.20.0 kubeadm-1.20.0 kubectl-1.20.0</span><br><span class="line">systemctl enable kubelet</span><br></pre></td></tr></table></figure>

<h2 id="4-部署Kubernetes-Master"><a href="#4-部署Kubernetes-Master" class="headerlink" title="4. 部署Kubernetes Master"></a>4. 部署Kubernetes Master</h2><p><a href="https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm-init/#config-file">https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm-init/#config-file</a> </p>
<p><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#initializing-your-control-plane-node">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#initializing-your-control-plane-node</a> </p>
<p>在192.168.81.57（Master）执行。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubeadm init \</span><br><span class="line">  --apiserver-advertise-address=192.168.81.57 \</span><br><span class="line">  --image-repository registry.aliyuncs.com/google_containers \</span><br><span class="line">  --kubernetes-version v1.20.0 \</span><br><span class="line">  --service-cidr=10.96.0.0/12 \</span><br><span class="line">  --pod-network-cidr=10.244.0.0/16 \</span><br><span class="line">  --ignore-preflight-errors=all</span><br></pre></td></tr></table></figure>

<ul>
<li>–apiserver-advertise-address 集群通告地址</li>
<li>–image-repository  由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址</li>
<li>–kubernetes-version K8s版本，与上面安装的一致</li>
<li>–service-cidr 集群内部虚拟网络，Pod统一访问入口</li>
<li>–pod-network-cidr Pod网络，，与下面部署的CNI网络组件yaml中保持一致</li>
</ul>
<p>或者使用配置文件引导：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi kubeadm.conf</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta2</span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: v1.20.0</span><br><span class="line">imageRepository: registry.aliyuncs.com/google_containers </span><br><span class="line">networking:</span><br><span class="line">  podSubnet: 10.244.0.0/16 </span><br><span class="line">  serviceSubnet: 10.96.0.0/12 </span><br><span class="line"></span><br><span class="line">kubeadm init --config kubeadm.conf --ignore-preflight-errors=all  </span><br></pre></td></tr></table></figure>



<p>拷贝kubectl使用的连接k8s认证文件到默认路径：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">[root@k8s-master ~]<span class="comment"># ll .kube/config </span></span><br><span class="line">-rw------- 1 root root 5569 3月  12 11:58 .kube/config</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br><span class="line">NAME               STATUS     ROLES            AGE   VERSION</span><br><span class="line">localhost.localdomain   NotReady   control-plane,master   20s   v1.20.0</span><br></pre></td></tr></table></figure>



<h2 id="5-加入Kubernetes-Node"><a href="#5-加入Kubernetes-Node" class="headerlink" title="5. 加入Kubernetes Node"></a>5. 加入Kubernetes Node</h2><p>在192.168.81.58/59（Node）执行。</p>
<p>向集群添加新节点，执行在kubeadm init输出的kubeadm join命令：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">kubeadm join 192.168.81.57:6443 --token tqxl1u.8vwoeza99jxzgoi0 \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:48321ed1651b239cee9dd3b482a24e9deee1e48c7ca3b34cfa429524538275ba </span><br></pre></td></tr></table></figure>

<p>默认token有效期为24小时，当过期之后，该token就不可用了。这时就需要重新创建token，可以直接使用命令快捷生成：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubeadm token create --print-join-command</span><br></pre></td></tr></table></figure>

<p><a href="https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-join/">https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-join/</a></p>
<h2 id="6-部署容器网络（CNI）"><a href="#6-部署容器网络（CNI）" class="headerlink" title="6. 部署容器网络（CNI）"></a>6. 部署容器网络（CNI）</h2><p><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network</a> </p>
<p>注意：只需要部署下面其中一个，推荐Calico。</p>
<p>Calico是一个纯三层的数据中心网络方案，Calico支持广泛的平台，包括Kubernetes、OpenStack等。</p>
<p>Calico 在每一个计算节点利用 Linux Kernel 实现了一个高效的虚拟路由器（ vRouter） 来负责数据转发，而每个 vRouter 通过 BGP 协议负责把自己上运行的 workload 的路由信息向整个 Calico 网络内传播。</p>
<p>此外，Calico  项目还实现了 Kubernetes 网络策略，提供ACL功能。</p>
<p> <a href="https://docs.projectcalico.org/getting-started/kubernetes/quickstart">https://docs.projectcalico.org/getting-started/kubernetes/quickstart</a> </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://docs.projectcalico.org/manifests/calico.yaml</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改yaml以下内容 IP地址段与上述init地址段保持一致</span></span><br><span class="line">[root@k8s-master ~]# vim calico.yaml</span><br><span class="line">            - name: CALICO_IPV4POOL_CIDR</span><br><span class="line">              value: &quot;10.244.0.0/16&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>下载完后还需要修改里面定义Pod网络（CALICO_IPV4POOL_CIDR），与前面kubeadm init指定的一样</p>
<p>修改完后应用清单：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl apply -f calico.yaml</span><br><span class="line">kubectl get pods -n kube-system</span><br></pre></td></tr></table></figure>

<h2 id="7-测试kubernetes集群"><a href="#7-测试kubernetes集群" class="headerlink" title="7. 测试kubernetes集群"></a>7. 测试kubernetes集群</h2><ul>
<li>验证Pod工作</li>
<li>验证Pod网络通信</li>
<li>验证DNS解析</li>
</ul>
<p>在Kubernetes集群中创建一个pod，验证是否正常运行：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl create deployment nginx --image=nginx</span><br><span class="line">kubectl expose deployment nginx --port=80 --type=NodePort</span><br><span class="line">[root@k8s-master ~]# kubectl expose deployment web --port=80 --target-port=80 --type=NodePort</span><br><span class="line"></span><br><span class="line">kubectl get pod,svc</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看 master 组件状态</span></span><br><span class="line">[root@k8s-master ~]# kubectl get cs</span><br><span class="line">Warning: v1 ComponentStatus is deprecated in v1.19+</span><br><span class="line">NAME                 STATUS      MESSAGE                                                                                       ERROR</span><br><span class="line">scheduler            Unhealthy   Get &quot;http://127.0.0.1:10251/healthz&quot;: dial tcp 127.0.0.1:10251: connect: connection refused   </span><br><span class="line">controller-manager   Unhealthy   Get &quot;http://127.0.0.1:10252/healthz&quot;: dial tcp 127.0.0.1:10252: connect: connection refused   </span><br><span class="line">etcd-0               Healthy     &#123;&quot;health&quot;:&quot;true&quot;&#125;  </span><br><span class="line"></span><br><span class="line">查看 master 组件不健康，估计版本小bug，不影响使用，如果要修复：</span><br><span class="line">打开两个文件：</span><br><span class="line">/etc/kubernetes/manifests/kube-controller-manager.yaml</span><br><span class="line">/etc/kubernetes/manifests/kube-scheduler.yaml</span><br><span class="line"><span class="meta">#</span><span class="bash">注释掉 --port=0，开启本地非安全端口，然后systemctl restart kubelet</span></span><br></pre></td></tr></table></figure>

<p>访问地址：<a href="http://NodeIP:Port">http://NodeIP:Port</a>  </p>
<h2 id="8-部署-Dashboard"><a href="#8-部署-Dashboard" class="headerlink" title="8. 部署 Dashboard"></a>8. 部署 Dashboard</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.3/aio/deploy/recommended.yaml</span><br></pre></td></tr></table></figure>

<p>默认Dashboard只能集群内部访问，修改Service为NodePort类型，暴露到外部：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi recommended.yaml</span><br><span class="line">...</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 443</span><br><span class="line">      targetPort: 8443</span><br><span class="line">      nodePort: 30001</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  type: NodePort</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">kubectl apply -f recommended.yaml</span><br><span class="line">kubectl get pods -n kubernetes-dashboard</span><br><span class="line">NAME                                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">dashboard-metrics-scraper-6b4884c9d5-gl8nr   1/1     Running   0          13m</span><br><span class="line">kubernetes-dashboard-7f99b75bf4-89cds        1/1     Running   0          13m$ vi recommended.yaml...kind: ServiceapiVersion: v1metadata:  labels:    k8s-app: kubernetes-dashboard  name: kubernetes-dashboard  namespace: kubernetes-dashboardspec:  ports:    - port: 443      targetPort: 8443      nodePort: 30001  selector:    k8s-app: kubernetes-dashboard  type: NodePort...$ kubectl apply -f recommended.yaml$ kubectl get pods -n kubernetes-dashboardNAME                                         READY   STATUS    RESTARTS   AGEdashboard-metrics-scraper-6b4884c9d5-gl8nr   1/1     Running   0          13mkubernetes-dashboard-7f99b75bf4-89cds        1/1     Running   0          13m</span><br></pre></td></tr></table></figure>

<p>访问地址：<a href="https://nodeip:30001/">https://NodeIP:30001</a></p>
<p>创建service account并绑定默认cluster-admin管理员集群角色：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建用户</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create serviceaccount dashboard-admin -n kube-system</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 用户授权</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取用户Token</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl describe secrets -n kube-system $(kubectl -n kube-system get secret | awk <span class="string">&#x27;/dashboard-admin/&#123;print $1&#125;&#x27;</span>)</span></span><br></pre></td></tr></table></figure>

<p>使用输出的token登录Dashboard。</p>
<h2 id="9-切换容器引擎为Containerd"><a href="#9-切换容器引擎为Containerd" class="headerlink" title="9. 切换容器引擎为Containerd"></a>9. 切换容器引擎为Containerd</h2><p><a href="https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/#containerd">https://kubernetes.io/zh/docs/setup/production-environment/container-runtimes/#containerd</a></p>
<p>1、配置先决条件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/containerd.conf</span><br><span class="line">overlay</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">sudo modprobe overlay</span><br><span class="line">sudo modprobe br_netfilter</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置必需的 sysctl 参数，这些参数在重新启动后仍然存在。</span></span><br><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/99-kubernetes-cri.conf</span><br><span class="line">net.bridge.bridge-nf-call-iptables  = 1</span><br><span class="line">net.ipv4.ip_forward                 = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">EOF</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Apply sysctl params without reboot</span></span><br><span class="line">sudo sysctl --system</span><br></pre></td></tr></table></figure>

<p>2、安装containerd</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装 containerd</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 设置仓库</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## 安装所需包</span></span></span><br><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加 docker 仓库</span></span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加 contoinerd</span></span><br><span class="line">yum update -y &amp;&amp; sudo yum install -y containerd.io</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置 contoinerd</span></span><br><span class="line">mkdir -p /etc/containerd</span><br><span class="line">containerd config default | sudo tee /etc/containerd/config.toml</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启 contoinerd</span></span><br><span class="line">systemctl restart containerd</span><br></pre></td></tr></table></figure>

<p>3、修改配置文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /etc/containerd/config.toml</span><br><span class="line">   [plugins.&quot;io.containerd.grpc.v1.cri&quot;]</span><br><span class="line">      sandbox_image = &quot;registry.aliyuncs.com/google_containers/pause:3.2&quot;  </span><br><span class="line">         ...			# 改为国内地址</span><br><span class="line">         [plugins.&quot;io.containerd.grpc.v1.cri&quot;.containerd.runtimes.runc.options]</span><br><span class="line">             SystemdCgroup = true</span><br><span class="line">             ...		# Cgroup驱动</span><br><span class="line">        [plugins.&quot;io.containerd.grpc.v1.cri&quot;.registry.mirrors.&quot;docker.io&quot;]</span><br><span class="line">          endpoint = [&quot;https://b9pmyelo.mirror.aliyuncs.com&quot;]</span><br><span class="line">          # 改为阿里云加速器</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>4、配置kubelet使用containerd</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /etc/sysconfig/kubelet </span><br><span class="line">KUBELET_EXTRA_ARGS=--container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock --cgroup-driver=systemd</span><br><span class="line"></span><br><span class="line">systemctl stop docker</span><br><span class="line">systemctl restart kubelet</span><br><span class="line">journalctl -u kubelet </span><br></pre></td></tr></table></figure>



<p>5、验证</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get node -o wide</span><br><span class="line"></span><br><span class="line">k8s-node1  xxx  containerd://1.4.4</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>k8s</tag>
      </tags>
  </entry>
</search>
